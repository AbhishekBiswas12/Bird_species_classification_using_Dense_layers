{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d646904b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda activate tf-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "968a8c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d436dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('x_train2.npy')\n",
    "y_train = np.load('y_train3.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fe92913",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_unique = np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e87e50be",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train2 = []\n",
    "for y in y_train:\n",
    "    y1 = 0\n",
    "    for i in range(len(y_unique)):\n",
    "        if y == y_unique[i]:\n",
    "            y1 = i\n",
    "    y_train2.append(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72ecc3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8,\n",
       " 345,\n",
       " 131,\n",
       " 283,\n",
       " 205,\n",
       " 303,\n",
       " 232,\n",
       " 220,\n",
       " 1,\n",
       " 39,\n",
       " 61,\n",
       " 355,\n",
       " 130,\n",
       " 202,\n",
       " 290,\n",
       " 78,\n",
       " 114,\n",
       " 119,\n",
       " 369,\n",
       " 316,\n",
       " 265,\n",
       " 273,\n",
       " 21,\n",
       " 342,\n",
       " 122,\n",
       " 81,\n",
       " 211,\n",
       " 152,\n",
       " 365,\n",
       " 92,\n",
       " 6,\n",
       " 385,\n",
       " 373,\n",
       " 115,\n",
       " 387,\n",
       " 284,\n",
       " 189,\n",
       " 177,\n",
       " 180,\n",
       " 104,\n",
       " 176,\n",
       " 347,\n",
       " 350,\n",
       " 139,\n",
       " 1,\n",
       " 141,\n",
       " 398,\n",
       " 326,\n",
       " 379,\n",
       " 224,\n",
       " 14,\n",
       " 97,\n",
       " 60,\n",
       " 276,\n",
       " 117,\n",
       " 323,\n",
       " 147,\n",
       " 209,\n",
       " 165,\n",
       " 144,\n",
       " 144,\n",
       " 163,\n",
       " 271,\n",
       " 319,\n",
       " 217,\n",
       " 181,\n",
       " 207,\n",
       " 101,\n",
       " 77,\n",
       " 102,\n",
       " 230,\n",
       " 277,\n",
       " 243,\n",
       " 325,\n",
       " 44,\n",
       " 86,\n",
       " 383,\n",
       " 49,\n",
       " 117,\n",
       " 333,\n",
       " 341,\n",
       " 351,\n",
       " 159,\n",
       " 316,\n",
       " 335,\n",
       " 98,\n",
       " 166,\n",
       " 173,\n",
       " 98,\n",
       " 68,\n",
       " 235,\n",
       " 302,\n",
       " 219,\n",
       " 193,\n",
       " 181,\n",
       " 136,\n",
       " 310,\n",
       " 259,\n",
       " 258,\n",
       " 55,\n",
       " 58,\n",
       " 174,\n",
       " 388,\n",
       " 251,\n",
       " 161,\n",
       " 342,\n",
       " 105,\n",
       " 397,\n",
       " 171,\n",
       " 214,\n",
       " 169,\n",
       " 216,\n",
       " 76,\n",
       " 117,\n",
       " 184,\n",
       " 41,\n",
       " 343,\n",
       " 168,\n",
       " 120,\n",
       " 287,\n",
       " 27,\n",
       " 126,\n",
       " 259,\n",
       " 364,\n",
       " 359,\n",
       " 317,\n",
       " 116,\n",
       " 19,\n",
       " 17,\n",
       " 292,\n",
       " 215,\n",
       " 278,\n",
       " 84,\n",
       " 279,\n",
       " 200,\n",
       " 378,\n",
       " 310,\n",
       " 181,\n",
       " 116,\n",
       " 253,\n",
       " 43,\n",
       " 26,\n",
       " 370,\n",
       " 45,\n",
       " 56,\n",
       " 183,\n",
       " 1,\n",
       " 322,\n",
       " 251,\n",
       " 213,\n",
       " 106,\n",
       " 316,\n",
       " 305,\n",
       " 159,\n",
       " 407,\n",
       " 337,\n",
       " 38,\n",
       " 183,\n",
       " 231,\n",
       " 265,\n",
       " 174,\n",
       " 409,\n",
       " 113,\n",
       " 73,\n",
       " 210,\n",
       " 293,\n",
       " 365,\n",
       " 400,\n",
       " 296,\n",
       " 102,\n",
       " 110,\n",
       " 405,\n",
       " 94,\n",
       " 203,\n",
       " 177,\n",
       " 96,\n",
       " 108,\n",
       " 237,\n",
       " 311,\n",
       " 361,\n",
       " 314,\n",
       " 36,\n",
       " 307,\n",
       " 19,\n",
       " 25,\n",
       " 189,\n",
       " 296,\n",
       " 67,\n",
       " 169,\n",
       " 282,\n",
       " 294,\n",
       " 176,\n",
       " 97,\n",
       " 363,\n",
       " 16,\n",
       " 70,\n",
       " 26,\n",
       " 187,\n",
       " 282,\n",
       " 149,\n",
       " 301,\n",
       " 10,\n",
       " 371,\n",
       " 119,\n",
       " 162,\n",
       " 125,\n",
       " 83,\n",
       " 16,\n",
       " 27,\n",
       " 198,\n",
       " 297,\n",
       " 318,\n",
       " 10,\n",
       " 28,\n",
       " 91,\n",
       " 74,\n",
       " 74,\n",
       " 266,\n",
       " 16,\n",
       " 218,\n",
       " 163,\n",
       " 113,\n",
       " 318,\n",
       " 57,\n",
       " 332,\n",
       " 152,\n",
       " 46,\n",
       " 336,\n",
       " 91,\n",
       " 30,\n",
       " 397,\n",
       " 258,\n",
       " 220,\n",
       " 186,\n",
       " 74,\n",
       " 195,\n",
       " 226,\n",
       " 276,\n",
       " 342,\n",
       " 296,\n",
       " 182,\n",
       " 379,\n",
       " 314,\n",
       " 195,\n",
       " 393,\n",
       " 165,\n",
       " 323,\n",
       " 356,\n",
       " 207,\n",
       " 237,\n",
       " 262,\n",
       " 153,\n",
       " 185,\n",
       " 47,\n",
       " 383,\n",
       " 381,\n",
       " 46,\n",
       " 407,\n",
       " 127,\n",
       " 384,\n",
       " 258,\n",
       " 319,\n",
       " 1,\n",
       " 355,\n",
       " 13,\n",
       " 81,\n",
       " 107,\n",
       " 96,\n",
       " 285,\n",
       " 85,\n",
       " 105,\n",
       " 9,\n",
       " 183,\n",
       " 136,\n",
       " 363,\n",
       " 189,\n",
       " 165,\n",
       " 119,\n",
       " 278,\n",
       " 188,\n",
       " 329,\n",
       " 386,\n",
       " 259,\n",
       " 34,\n",
       " 192,\n",
       " 211,\n",
       " 114,\n",
       " 183,\n",
       " 326,\n",
       " 55,\n",
       " 99,\n",
       " 312,\n",
       " 298,\n",
       " 180,\n",
       " 311,\n",
       " 316,\n",
       " 134,\n",
       " 245,\n",
       " 117,\n",
       " 124,\n",
       " 12,\n",
       " 269,\n",
       " 156,\n",
       " 302,\n",
       " 408,\n",
       " 101,\n",
       " 403,\n",
       " 221,\n",
       " 216,\n",
       " 375,\n",
       " 367,\n",
       " 3,\n",
       " 214,\n",
       " 41,\n",
       " 13,\n",
       " 383,\n",
       " 221,\n",
       " 380,\n",
       " 273,\n",
       " 137,\n",
       " 246,\n",
       " 323,\n",
       " 72,\n",
       " 40,\n",
       " 192,\n",
       " 218,\n",
       " 190,\n",
       " 392,\n",
       " 324,\n",
       " 279,\n",
       " 395,\n",
       " 333,\n",
       " 226,\n",
       " 80,\n",
       " 265,\n",
       " 129,\n",
       " 82,\n",
       " 148,\n",
       " 48,\n",
       " 113,\n",
       " 347,\n",
       " 39,\n",
       " 60,\n",
       " 126,\n",
       " 233,\n",
       " 409,\n",
       " 315,\n",
       " 81,\n",
       " 140,\n",
       " 145,\n",
       " 371,\n",
       " 275,\n",
       " 375,\n",
       " 316,\n",
       " 309,\n",
       " 31,\n",
       " 225,\n",
       " 182,\n",
       " 149,\n",
       " 408,\n",
       " 52,\n",
       " 340,\n",
       " 194,\n",
       " 250,\n",
       " 170,\n",
       " 100,\n",
       " 190,\n",
       " 124,\n",
       " 307,\n",
       " 324,\n",
       " 100,\n",
       " 208,\n",
       " 313,\n",
       " 273,\n",
       " 108,\n",
       " 30,\n",
       " 70,\n",
       " 150,\n",
       " 88,\n",
       " 30,\n",
       " 405,\n",
       " 145,\n",
       " 33,\n",
       " 231,\n",
       " 360,\n",
       " 106,\n",
       " 30,\n",
       " 252,\n",
       " 140,\n",
       " 229,\n",
       " 90,\n",
       " 294,\n",
       " 248,\n",
       " 1,\n",
       " 122,\n",
       " 3,\n",
       " 368,\n",
       " 322,\n",
       " 229,\n",
       " 54,\n",
       " 248,\n",
       " 359,\n",
       " 327,\n",
       " 117,\n",
       " 196,\n",
       " 47,\n",
       " 327,\n",
       " 363,\n",
       " 338,\n",
       " 68,\n",
       " 85,\n",
       " 152,\n",
       " 399,\n",
       " 384,\n",
       " 73,\n",
       " 128,\n",
       " 99,\n",
       " 407,\n",
       " 226,\n",
       " 240,\n",
       " 115,\n",
       " 145,\n",
       " 9,\n",
       " 312,\n",
       " 241,\n",
       " 245,\n",
       " 309,\n",
       " 192,\n",
       " 222,\n",
       " 392,\n",
       " 29,\n",
       " 240,\n",
       " 176,\n",
       " 220,\n",
       " 222,\n",
       " 63,\n",
       " 66,\n",
       " 64,\n",
       " 127,\n",
       " 389,\n",
       " 410,\n",
       " 65,\n",
       " 135,\n",
       " 251,\n",
       " 112,\n",
       " 383,\n",
       " 396,\n",
       " 361,\n",
       " 69,\n",
       " 246,\n",
       " 204,\n",
       " 368,\n",
       " 370,\n",
       " 124,\n",
       " 256,\n",
       " 156,\n",
       " 162,\n",
       " 153,\n",
       " 229,\n",
       " 219,\n",
       " 245,\n",
       " 313,\n",
       " 215,\n",
       " 386,\n",
       " 218,\n",
       " 85,\n",
       " 206,\n",
       " 127,\n",
       " 375,\n",
       " 339,\n",
       " 288,\n",
       " 328,\n",
       " 307,\n",
       " 211,\n",
       " 280,\n",
       " 206,\n",
       " 307,\n",
       " 74,\n",
       " 255,\n",
       " 178,\n",
       " 69,\n",
       " 43,\n",
       " 29,\n",
       " 232,\n",
       " 278,\n",
       " 128,\n",
       " 259,\n",
       " 103,\n",
       " 114,\n",
       " 254,\n",
       " 44,\n",
       " 135,\n",
       " 303,\n",
       " 22,\n",
       " 14,\n",
       " 372,\n",
       " 395,\n",
       " 66,\n",
       " 194,\n",
       " 393,\n",
       " 144,\n",
       " 376,\n",
       " 311,\n",
       " 47,\n",
       " 383,\n",
       " 387,\n",
       " 151,\n",
       " 80,\n",
       " 289,\n",
       " 25,\n",
       " 40,\n",
       " 7,\n",
       " 140,\n",
       " 214,\n",
       " 317,\n",
       " 335,\n",
       " 324,\n",
       " 401,\n",
       " 188,\n",
       " 47,\n",
       " 333,\n",
       " 11,\n",
       " 273,\n",
       " 164,\n",
       " 383,\n",
       " 249,\n",
       " 238,\n",
       " 321,\n",
       " 167,\n",
       " 15,\n",
       " 360,\n",
       " 340,\n",
       " 77,\n",
       " 105,\n",
       " 131,\n",
       " 13,\n",
       " 25,\n",
       " 78,\n",
       " 146,\n",
       " 207,\n",
       " 26,\n",
       " 336,\n",
       " 230,\n",
       " 298,\n",
       " 98,\n",
       " 25,\n",
       " 278,\n",
       " 75,\n",
       " 241,\n",
       " 27,\n",
       " 69,\n",
       " 372,\n",
       " 201,\n",
       " 86,\n",
       " 197,\n",
       " 201,\n",
       " 400,\n",
       " 123,\n",
       " 254,\n",
       " 94,\n",
       " 201,\n",
       " 292,\n",
       " 73,\n",
       " 253,\n",
       " 170,\n",
       " 322,\n",
       " 349,\n",
       " 98,\n",
       " 274,\n",
       " 237,\n",
       " 169,\n",
       " 74,\n",
       " 337,\n",
       " 76,\n",
       " 410,\n",
       " 179,\n",
       " 44,\n",
       " 64,\n",
       " 298,\n",
       " 316,\n",
       " 115,\n",
       " 366,\n",
       " 55,\n",
       " 336,\n",
       " 92,\n",
       " 385,\n",
       " 69,\n",
       " 72,\n",
       " 262,\n",
       " 207,\n",
       " 148,\n",
       " 319,\n",
       " 165,\n",
       " 69,\n",
       " 100,\n",
       " 388,\n",
       " 239,\n",
       " 289,\n",
       " 167,\n",
       " 234,\n",
       " 26,\n",
       " 90,\n",
       " 360,\n",
       " 218,\n",
       " 332,\n",
       " 191,\n",
       " 144,\n",
       " 54,\n",
       " 5,\n",
       " 375,\n",
       " 46,\n",
       " 380,\n",
       " 271,\n",
       " 162,\n",
       " 101,\n",
       " 275,\n",
       " 304,\n",
       " 164,\n",
       " 356,\n",
       " 292,\n",
       " 377,\n",
       " 223,\n",
       " 203,\n",
       " 213,\n",
       " 94,\n",
       " 389,\n",
       " 6,\n",
       " 220,\n",
       " 128,\n",
       " 28,\n",
       " 349,\n",
       " 405,\n",
       " 24,\n",
       " 221,\n",
       " 326,\n",
       " 104,\n",
       " 319,\n",
       " 10,\n",
       " 136,\n",
       " 320,\n",
       " 41,\n",
       " 166,\n",
       " 391,\n",
       " 137,\n",
       " 241,\n",
       " 258,\n",
       " 360,\n",
       " 354,\n",
       " 176,\n",
       " 303,\n",
       " 133,\n",
       " 55,\n",
       " 83,\n",
       " 222,\n",
       " 360,\n",
       " 267,\n",
       " 141,\n",
       " 369,\n",
       " 261,\n",
       " 393,\n",
       " 250,\n",
       " 300,\n",
       " 133,\n",
       " 150,\n",
       " 389,\n",
       " 241,\n",
       " 293,\n",
       " 149,\n",
       " 184,\n",
       " 137,\n",
       " 250,\n",
       " 348,\n",
       " 252,\n",
       " 63,\n",
       " 258,\n",
       " 131,\n",
       " 79,\n",
       " 133,\n",
       " 12,\n",
       " 392,\n",
       " 106,\n",
       " 120,\n",
       " 287,\n",
       " 402,\n",
       " 401,\n",
       " 289,\n",
       " 185,\n",
       " 86,\n",
       " 318,\n",
       " 289,\n",
       " 307,\n",
       " 384,\n",
       " 273,\n",
       " 389,\n",
       " 89,\n",
       " 100,\n",
       " 269,\n",
       " 360,\n",
       " 72,\n",
       " 36,\n",
       " 284,\n",
       " 181,\n",
       " 82,\n",
       " 43,\n",
       " 361,\n",
       " 90,\n",
       " 33,\n",
       " 282,\n",
       " 301,\n",
       " 313,\n",
       " 7,\n",
       " 246,\n",
       " 96,\n",
       " 298,\n",
       " 151,\n",
       " 407,\n",
       " 75,\n",
       " 396,\n",
       " 22,\n",
       " 343,\n",
       " 87,\n",
       " 63,\n",
       " 321,\n",
       " 35,\n",
       " 140,\n",
       " 66,\n",
       " 26,\n",
       " 206,\n",
       " 91,\n",
       " 37,\n",
       " 173,\n",
       " 242,\n",
       " 114,\n",
       " 257,\n",
       " 48,\n",
       " 1,\n",
       " 175,\n",
       " 174,\n",
       " 29,\n",
       " 137,\n",
       " 45,\n",
       " 270,\n",
       " 376,\n",
       " 0,\n",
       " 78,\n",
       " 182,\n",
       " 354,\n",
       " 395,\n",
       " 208,\n",
       " 112,\n",
       " 312,\n",
       " 339,\n",
       " 84,\n",
       " 227,\n",
       " 45,\n",
       " 227,\n",
       " 15,\n",
       " 186,\n",
       " 315,\n",
       " 100,\n",
       " 362,\n",
       " 131,\n",
       " 391,\n",
       " 314,\n",
       " 255,\n",
       " 357,\n",
       " 157,\n",
       " 191,\n",
       " 135,\n",
       " 286,\n",
       " 205,\n",
       " 389,\n",
       " 328,\n",
       " 98,\n",
       " 1,\n",
       " 292,\n",
       " 157,\n",
       " 272,\n",
       " 290,\n",
       " 7,\n",
       " 190,\n",
       " 242,\n",
       " 171,\n",
       " 73,\n",
       " 316,\n",
       " 365,\n",
       " 393,\n",
       " 185,\n",
       " 12,\n",
       " 215,\n",
       " 403,\n",
       " 67,\n",
       " 16,\n",
       " 362,\n",
       " 380,\n",
       " 219,\n",
       " 373,\n",
       " 81,\n",
       " 135,\n",
       " 82,\n",
       " 234,\n",
       " 196,\n",
       " 39,\n",
       " 165,\n",
       " 254,\n",
       " 318,\n",
       " 144,\n",
       " 269,\n",
       " 398,\n",
       " 197,\n",
       " 137,\n",
       " 52,\n",
       " 371,\n",
       " 388,\n",
       " 45,\n",
       " 385,\n",
       " 16,\n",
       " 97,\n",
       " 248,\n",
       " 208,\n",
       " 305,\n",
       " 7,\n",
       " 347,\n",
       " 45,\n",
       " 180,\n",
       " 247,\n",
       " 267,\n",
       " 292,\n",
       " 22,\n",
       " 123,\n",
       " 388,\n",
       " 260,\n",
       " 211,\n",
       " 396,\n",
       " 5,\n",
       " 126,\n",
       " 321,\n",
       " 242,\n",
       " 186,\n",
       " 201,\n",
       " 1,\n",
       " 26,\n",
       " 244,\n",
       " 260,\n",
       " 323,\n",
       " 59,\n",
       " 137,\n",
       " 243,\n",
       " 364,\n",
       " 149,\n",
       " 176,\n",
       " 171,\n",
       " 26,\n",
       " 363,\n",
       " 170,\n",
       " 187,\n",
       " 36,\n",
       " 299,\n",
       " 248,\n",
       " 303,\n",
       " 101,\n",
       " 221,\n",
       " 214,\n",
       " 404,\n",
       " 54,\n",
       " 385,\n",
       " 53,\n",
       " 152,\n",
       " 148,\n",
       " 310,\n",
       " 404,\n",
       " 42,\n",
       " 37,\n",
       " 77,\n",
       " 222,\n",
       " 131,\n",
       " 378,\n",
       " 272,\n",
       " 245,\n",
       " 204,\n",
       " 207,\n",
       " 73,\n",
       " 281,\n",
       " 162,\n",
       " 149,\n",
       " 263,\n",
       " 107,\n",
       " 267,\n",
       " 396,\n",
       " 267,\n",
       " 29,\n",
       " 45,\n",
       " 57,\n",
       " 389,\n",
       " 185,\n",
       " 122,\n",
       " 109,\n",
       " 262,\n",
       " 328,\n",
       " 357,\n",
       " 33,\n",
       " 300,\n",
       " 333,\n",
       " 179,\n",
       " 261,\n",
       " 383,\n",
       " 119,\n",
       " 356,\n",
       " 183,\n",
       " 33,\n",
       " 76,\n",
       " 245,\n",
       " 281,\n",
       " 170,\n",
       " 61,\n",
       " 99,\n",
       " 275,\n",
       " 376,\n",
       " 279,\n",
       " 265,\n",
       " 310,\n",
       " 180,\n",
       " 174,\n",
       " 35,\n",
       " 365,\n",
       " 167,\n",
       " 263,\n",
       " 379,\n",
       " 148,\n",
       " 29,\n",
       " 280,\n",
       " 14,\n",
       " 215,\n",
       " 285,\n",
       " 399,\n",
       " 34,\n",
       " 262,\n",
       " 202,\n",
       " 172,\n",
       " 322,\n",
       " 195,\n",
       " 333,\n",
       " 37,\n",
       " 359,\n",
       " 161,\n",
       " 265,\n",
       " 244,\n",
       " 387,\n",
       " 382,\n",
       " 259,\n",
       " 237,\n",
       " 183,\n",
       " 243,\n",
       " 222,\n",
       " 410,\n",
       " 292,\n",
       " 64,\n",
       " 50,\n",
       " 267,\n",
       " 99,\n",
       " 258,\n",
       " 46,\n",
       " 234,\n",
       " 410,\n",
       " 18,\n",
       " 178,\n",
       " 205,\n",
       " 76,\n",
       " 52,\n",
       " 250,\n",
       " 191,\n",
       " 396,\n",
       " 85,\n",
       " 168,\n",
       " 64,\n",
       " 286,\n",
       " 251,\n",
       " 90,\n",
       " 88,\n",
       " 13,\n",
       " 398,\n",
       " 276,\n",
       " 275,\n",
       " 200,\n",
       " 183,\n",
       " 187,\n",
       " 10,\n",
       " 109,\n",
       " 251,\n",
       " 181,\n",
       " 346,\n",
       " 68,\n",
       " 245,\n",
       " 315,\n",
       " 374,\n",
       " 153,\n",
       " 115,\n",
       " 28,\n",
       " 399,\n",
       " 270,\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff27f373",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7ae1d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train2)\n",
    "np.save('y_train3.npy', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8591f8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46710"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ffbdf23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46710"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6abdf13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46710, 3136)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7f1ea9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46710,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73492517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adc1251",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c90cca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Dense(units = x_train.shape[1], input_dim = x_train.shape[1], activation = 'relu', activity_regularizer = tf.keras.regularizers.L2(0.1)),\n",
    "        Dense(units = (x_train.shape[1])/3, activation = 'relu', activity_regularizer = tf.keras.regularizers.L2(0.1)),\n",
    "        Dense(units = (x_train.shape[1])/3,activation = 'relu', activity_regularizer = tf.keras.regularizers.L2(0.1)),\n",
    "        Dense(units = (x_train.shape[1])/3,activation = 'relu', activity_regularizer = tf.keras.regularizers.L2(0.1)),\n",
    "        Dense(units = (x_train.shape[1])/9,activation = 'relu', activity_regularizer = tf.keras.regularizers.L2(0.1)),\n",
    "        Dense(units = 700,activation = 'relu', activity_regularizer = tf.keras.regularizers.L2(0.1)),\n",
    "        Dense(units = 411, activation = 'softmax'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "650eced0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 3136)              9837632   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1045)              3278165   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1045)              1093070   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1045)              1093070   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 348)               364008    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 700)               244300    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 411)               288111    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,198,356\n",
      "Trainable params: 16,198,356\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59570ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "             optimizer = tf.keras.optimizers.Adam(0.00000001), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95d402d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.uint8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8265c52",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8d1cc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# checkpoint_path = \"C:\\Users\\rohan\\Computer vision\\Bird Classification\\model1.ckpt\"\n",
    "checkpoint_dir = os.path.dirname('model2.ckpt')\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"model2.ckpt\",\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb4db7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x232823a4880>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('model2.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdb91038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-2.6853155e-02, -1.7214794e-02, -1.7341308e-02, ...,\n",
       "          4.2582853e-03, -2.2197478e-02, -3.5641130e-02],\n",
       "        [-1.1511651e-02,  1.7147668e-02, -6.5485602e-03, ...,\n",
       "         -1.8216918e-03,  3.1926538e-04, -1.9856911e-02],\n",
       "        [-3.3879329e-02, -2.0199640e-02, -1.1035396e-02, ...,\n",
       "         -1.8273434e-02, -2.9550482e-02,  1.1052534e-02],\n",
       "        ...,\n",
       "        [ 2.8251639e-02,  1.6333427e-02, -2.8085630e-02, ...,\n",
       "         -3.4920014e-02, -7.1524307e-03, -2.5905628e-02],\n",
       "        [-2.3474010e-02, -2.2424242e-02,  1.4723068e-03, ...,\n",
       "         -3.5474915e-02,  2.0537885e-02,  9.5064826e-03],\n",
       "        [-1.9995827e-02,  1.0195472e-02, -4.6270368e-05, ...,\n",
       "          1.9590052e-02,  5.8224401e-03, -3.7158499e-03]], dtype=float32),\n",
       " array([-0.00770718, -0.00644885, -0.00217193, ..., -0.00486651,\n",
       "        -0.00606083, -0.00835553], dtype=float32),\n",
       " array([[ 0.01428699,  0.03301504, -0.01682446, ...,  0.03458656,\n",
       "          0.01505344,  0.02218592],\n",
       "        [-0.03902259, -0.0168405 , -0.0249086 , ..., -0.04403361,\n",
       "         -0.00564643, -0.03436561],\n",
       "        [ 0.00743506, -0.00444491, -0.01558653, ...,  0.02285359,\n",
       "          0.01064763,  0.00742284],\n",
       "        ...,\n",
       "        [-0.02373341, -0.03262993,  0.04151827, ...,  0.01747518,\n",
       "          0.04316948, -0.01797763],\n",
       "        [-0.02221769, -0.02726505,  0.03624816, ..., -0.03116726,\n",
       "          0.02843192,  0.01149329],\n",
       "        [ 0.02016084, -0.03106777,  0.04468744, ..., -0.0040258 ,\n",
       "         -0.01263049,  0.00085986]], dtype=float32),\n",
       " array([-0.03173917, -0.00736911, -0.00939613, ..., -0.0473768 ,\n",
       "         0.05506589, -0.00996376], dtype=float32),\n",
       " array([[ 0.00089777, -0.03919965, -0.04870471, ...,  0.04017062,\n",
       "          0.06488648,  0.04883554],\n",
       "        [ 0.02123244, -0.02076817,  0.04438061, ..., -0.00569844,\n",
       "          0.03825885, -0.0707524 ],\n",
       "        [ 0.00513956, -0.02508302, -0.04526111, ...,  0.04170574,\n",
       "          0.12734583, -0.14150675],\n",
       "        ...,\n",
       "        [ 0.01626278,  0.00402358,  0.00306764, ..., -0.04517612,\n",
       "         -0.0548009 ,  0.03267161],\n",
       "        [-0.01150517, -0.03852891,  0.00557604, ...,  0.03914893,\n",
       "         -0.13939741, -0.03954472],\n",
       "        [-0.01310112,  0.03380558, -0.01433882, ..., -0.04613103,\n",
       "         -0.02302618,  0.01996379]], dtype=float32),\n",
       " array([-0.02552126, -0.03585651,  0.00752245, ...,  0.04041623,\n",
       "         0.0026578 , -0.03933943], dtype=float32),\n",
       " array([[-0.03952157, -0.00622961, -0.00272959, ...,  0.01123585,\n",
       "          0.01729354, -0.03412712],\n",
       "        [-0.04886192,  0.03840771,  0.02025743, ..., -0.0149457 ,\n",
       "         -0.02697   ,  0.04613391],\n",
       "        [-0.03918535,  0.0226218 , -0.05184365, ..., -0.03968347,\n",
       "         -0.01895602, -0.0330945 ],\n",
       "        ...,\n",
       "        [-0.02808859,  0.03658913,  0.03493716, ..., -0.00879261,\n",
       "          0.00037353,  0.03943468],\n",
       "        [-0.09421682, -0.0470475 , -0.02814803, ..., -0.01455442,\n",
       "          0.01455157, -0.01877382],\n",
       "        [-0.05417431, -0.06328733, -0.07731167, ..., -0.11052729,\n",
       "          0.00381866,  0.01554479]], dtype=float32),\n",
       " array([-0.01412948, -0.01447765, -0.01922171, ..., -0.01385413,\n",
       "        -0.01580527, -0.02367455], dtype=float32),\n",
       " array([[ 2.72225589e-02, -6.97372556e-02, -1.32910861e-02, ...,\n",
       "         -8.09478164e-02, -4.76707853e-02, -6.81419894e-02],\n",
       "        [-1.12639689e-04,  4.44479622e-02, -4.77673225e-02, ...,\n",
       "         -5.57052791e-02,  1.06713101e-02, -4.12676595e-02],\n",
       "        [-5.64123020e-02,  8.86678323e-02, -7.11141005e-02, ...,\n",
       "         -5.45176603e-02,  3.91931534e-02,  4.24665064e-02],\n",
       "        ...,\n",
       "        [-5.81721310e-03, -2.47040950e-02, -1.23617195e-01, ...,\n",
       "          3.08961626e-02, -1.86744824e-01, -5.27197719e-02],\n",
       "        [-1.25090793e-01,  7.18071908e-02, -4.72861193e-02, ...,\n",
       "         -5.17569035e-02,  4.02533486e-02,  1.53771983e-02],\n",
       "        [-4.66208756e-02,  1.84344314e-02, -6.96299747e-02, ...,\n",
       "         -7.95276370e-03, -5.27716316e-02, -1.01054907e-02]], dtype=float32),\n",
       " array([ 1.27166495e-01, -1.29639745e-01,  1.85992330e-01, -5.26240647e-01,\n",
       "         4.29542884e-02, -8.14114138e-02,  7.79482499e-02, -6.38046116e-02,\n",
       "        -2.49077201e-01,  4.18723859e-02, -6.95910305e-02,  2.19156802e-01,\n",
       "         4.62972075e-01, -2.00685143e-01,  3.52542959e-02, -1.35200083e-01,\n",
       "        -1.73460662e-01,  1.26627330e-02,  1.70641810e-01,  1.90642744e-01,\n",
       "         1.87017813e-01, -4.17430013e-01, -1.60998583e-01, -2.45607877e+00,\n",
       "        -8.45946074e-02, -1.69176519e-01, -5.99255227e-02,  2.28552055e-02,\n",
       "         2.02210113e-01, -3.96433324e-01,  3.19803983e-01,  1.35379255e-01,\n",
       "        -3.05991620e-01, -1.16435550e-01, -2.34817818e-01, -4.40948039e-01,\n",
       "         1.94902524e-01,  9.36435610e-02, -6.83133423e-01, -2.56153613e-01,\n",
       "        -3.84855300e-01,  2.24851742e-01,  1.15245290e-01, -2.04492003e-01,\n",
       "        -2.86001205e-01, -2.90203001e-02, -8.08963403e-02, -1.39368296e-01,\n",
       "         6.43048063e-02,  8.51716995e-02,  2.42263362e-01, -3.51122677e-01,\n",
       "        -2.75294155e-01, -4.78734747e-02, -1.35434687e-01, -2.25037754e-01,\n",
       "        -2.65357882e-01, -4.25930135e-02, -1.62805498e-01,  2.90776759e-01,\n",
       "         1.78936888e-02, -2.45076314e-01, -2.37570477e+00, -4.57089037e-01,\n",
       "         8.09699818e-02,  4.77172062e-02, -4.25199091e-01,  1.85064450e-01,\n",
       "        -5.15886009e-01, -7.06188381e-01,  7.52042700e-03, -1.80049509e-01,\n",
       "         1.81357503e-01, -3.75720888e-01, -2.16635644e-01, -2.17331037e-01,\n",
       "        -4.03456807e-01, -3.22707891e-01, -6.94161057e-02, -5.01708500e-02,\n",
       "         2.43670061e-01,  4.03138787e-01, -4.73335944e-03, -3.00277323e-01,\n",
       "        -1.69670247e-02, -1.33287236e-01, -7.47013807e-01, -6.91773713e-01,\n",
       "        -3.06115299e-02,  2.45841861e-01, -5.85094392e-01, -4.24680710e-01,\n",
       "         3.95972617e-02,  7.91708976e-02,  1.11275919e-01,  9.98222157e-02,\n",
       "         3.72377068e-01,  1.62277341e-01, -2.54489303e-01, -7.35786021e-01,\n",
       "        -1.14690602e-01, -3.02706569e-01,  2.74047464e-01, -4.59474511e-03,\n",
       "         1.78017139e-01, -5.89489788e-02,  2.02962458e-01,  3.37181687e-01,\n",
       "        -4.30569835e-02,  2.14925800e-02, -1.10975504e-01, -1.56170964e-01,\n",
       "         8.06869566e-02, -7.07985014e-02, -4.23208654e-01, -1.99861266e-02,\n",
       "        -2.87168384e-01, -1.49609774e-01,  3.02627552e-02, -1.29976735e-01,\n",
       "         3.02717865e-01, -1.37978550e-02,  3.28335948e-02, -3.65654454e-02,\n",
       "        -7.04344928e-01,  1.64748043e-01,  9.25133526e-02, -1.82593450e-01,\n",
       "         8.62888172e-02,  1.45965787e-02,  8.41867849e-02, -9.78388116e-02,\n",
       "        -1.19224176e-01, -2.82296568e-01,  1.72760695e-01, -1.31783932e-01,\n",
       "         1.35716513e-01,  1.28015399e-01,  2.18096182e-01,  2.10482076e-01,\n",
       "         2.25417331e-01, -3.80177647e-02, -2.36641908e+00, -8.92565250e-01,\n",
       "        -6.66544735e-01, -1.59939855e-01, -2.72801310e-01,  1.34582609e-01,\n",
       "         1.09853938e-01,  1.48706064e-01, -4.42405313e-01, -1.11034594e-01,\n",
       "         3.62103015e-01, -4.58164178e-02, -5.01086786e-02, -2.13384051e-02,\n",
       "        -3.19602311e-01,  2.68080890e-01, -2.28441551e-01,  2.46874765e-02,\n",
       "         1.54021680e-01, -1.28306061e-01, -4.20599766e-02,  7.74023458e-02,\n",
       "        -1.20023708e-03,  6.03621639e-03, -1.50967002e-01, -1.58014111e-02,\n",
       "        -1.13501303e-01,  8.93206373e-02,  1.74246758e-01, -2.08832547e-02,\n",
       "         2.54076034e-01, -9.49774534e-02, -3.48791108e-02, -9.01450068e-02,\n",
       "        -2.63632506e-01, -4.05504286e-01,  4.02781274e-03, -4.39330757e-01,\n",
       "         5.17009832e-02, -1.38823807e-01, -3.07677928e-02, -2.26168469e-01,\n",
       "         6.82082325e-02, -4.18838821e-02, -7.81927705e-02, -1.38307577e-02,\n",
       "         5.25250733e-02,  3.24473158e-02,  4.23318194e-03, -1.05146334e-01,\n",
       "        -5.19319177e-01, -1.80393413e-01,  2.05036700e-01, -2.52416521e-01,\n",
       "        -6.18981384e-02, -1.20134540e-01,  8.27883929e-02,  1.59927040e-01,\n",
       "         5.84141761e-02,  4.25131172e-01,  1.55214056e-01, -4.20776308e-01,\n",
       "        -2.60418057e-01,  3.25722843e-02, -7.36881495e-01,  3.28151792e-01,\n",
       "        -4.83981371e-01, -1.53187335e-01,  1.15352556e-01,  6.20260686e-02,\n",
       "         6.65705130e-02, -2.43432999e-01, -1.24057224e-02, -4.34501767e-01,\n",
       "        -1.75088733e-01, -1.83201000e-01, -3.47957015e-01,  2.29908228e-01,\n",
       "        -3.70736182e-01, -2.76308388e-01, -1.29421994e-01, -1.01513326e-01,\n",
       "        -2.52333105e-01, -6.42669022e-01, -1.01617694e-01, -1.36150077e-01,\n",
       "        -2.41374731e+00,  2.38447919e-01, -7.35412315e-02, -1.74598455e-01,\n",
       "         1.45849679e-02, -3.13768506e-01,  1.10592075e-01,  2.52064578e-02,\n",
       "        -6.10052943e-01, -2.90073961e-01,  2.79338360e-01,  3.41881573e-01,\n",
       "        -3.15093100e-01,  1.16590999e-01, -8.14106464e-01,  3.61178547e-01,\n",
       "        -1.12440512e-01, -5.32983959e-01,  6.37079179e-02,  1.09995358e-01,\n",
       "         2.61527568e-01,  4.32655424e-01,  1.48169979e-01,  6.22154884e-02,\n",
       "         2.33760383e-02, -1.45077109e-02, -4.80735928e-01,  2.23657652e-03,\n",
       "         1.70824945e-01,  1.56963050e-01,  7.06369281e-02, -1.14000373e-01,\n",
       "        -8.81428048e-02, -2.91940849e-02, -2.16897741e-01,  1.54021308e-01,\n",
       "         3.20991687e-02, -2.35089496e-01, -3.93538624e-02, -2.88058609e-01,\n",
       "         4.88821805e-01,  1.33959994e-01, -2.28801459e-01,  2.95993071e-02,\n",
       "         9.75596369e-04, -2.87476152e-01, -5.46745658e-02, -3.25049087e-02,\n",
       "         3.10657233e-01, -1.69091865e-01, -2.21509375e-02, -1.32201277e-02,\n",
       "        -4.62573841e-02, -4.88748923e-02,  5.46391070e-01,  7.25431144e-02,\n",
       "        -8.00251365e-02,  1.66105822e-01, -3.20932090e-01, -2.05801532e-01,\n",
       "        -1.89902693e-01, -1.27511183e-02, -4.58019346e-01,  1.96519252e-02,\n",
       "         1.11226968e-01, -2.27018759e-01,  2.78406888e-01,  7.38095194e-02,\n",
       "         2.40013912e-01, -3.61927859e-02, -1.11322939e-01, -2.67430097e-01,\n",
       "         1.34581298e-01,  1.82333797e-01,  1.76115587e-01, -1.91180423e-01,\n",
       "        -1.37810215e-01, -1.70654908e-01, -3.54677439e-02,  3.60297598e-02,\n",
       "        -1.06916223e-02, -2.77023405e-01, -1.34967893e-01,  1.35934547e-01,\n",
       "         2.56514340e-03, -1.20153263e-01, -5.92701659e-02,  3.37141424e-01,\n",
       "        -2.09962323e-01,  1.85400788e-02, -1.30493104e-01,  1.82439074e-01,\n",
       "        -8.01307987e-03, -9.30484906e-02,  7.93864354e-02, -1.32144436e-01,\n",
       "        -2.46643364e-01,  4.23509955e-01, -4.16727543e-01,  5.92778437e-02,\n",
       "        -1.33140206e-01, -2.64938831e-01, -1.00838017e+00, -1.60199070e+00,\n",
       "        -5.43918371e-01, -4.35580164e-02, -1.01393068e+00, -1.69502214e-01,\n",
       "        -3.93233627e-01, -1.48402005e-01, -1.61353624e+00,  9.31209996e-02,\n",
       "        -2.81032056e-01,  9.99364331e-02, -4.06890035e-01,  3.27218324e-01,\n",
       "        -2.02471882e-01, -3.09209496e-01, -5.17327011e-01,  3.19723010e-01,\n",
       "         3.21268767e-01,  6.75420016e-02, -3.58051062e-01, -7.71710515e-01,\n",
       "        -1.85515597e-01, -5.77202678e-01, -5.33422887e-01,  3.56541388e-03,\n",
       "        -3.06087226e-01, -6.95409238e-01, -5.04135311e-01, -2.73139656e-01,\n",
       "         2.44350970e-01, -2.62671173e-01, -4.07156199e-01, -9.26779881e-02,\n",
       "        -1.95243761e-01, -4.96358052e-03,  5.25045156e-01, -8.65557790e-02,\n",
       "         1.65318713e-01,  1.75825790e-01,  6.34137690e-02, -2.69201696e-01,\n",
       "         2.07713768e-01,  4.77871336e-02, -1.01183958e-01,  3.95792544e-01,\n",
       "         5.66504756e-03,  4.41924259e-02, -2.05073819e-01, -6.68491498e-02,\n",
       "         3.07085477e-02, -1.31595984e-01,  3.01041573e-01,  2.99235117e-02,\n",
       "        -8.58489498e-02, -3.28519158e-02, -5.70126511e-02, -1.50040656e-01,\n",
       "        -2.63490468e-01, -5.77670261e-02, -1.63910553e-01,  6.05207719e-02,\n",
       "         6.37737438e-02,  3.20722640e-01, -4.31679964e-01, -1.72088489e-01,\n",
       "         1.17278308e-01,  1.38017565e-01, -3.36354703e-01, -2.51109540e-01,\n",
       "        -2.68829077e-01, -4.45948571e-01, -1.50479302e-01, -2.42462695e-01,\n",
       "         1.49452299e-01, -5.70633113e-02, -2.83655226e-01,  6.06001377e-01,\n",
       "        -2.81883150e-01, -4.35900658e-01,  3.46031100e-01], dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e63c34ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration = 29.0\n",
      "\n",
      "Epoch 1/34\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.8260 - accuracy: 0.0270\n",
      "Epoch 1: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 58ms/step - loss: 5.8260 - accuracy: 0.0270\n",
      "Epoch 2/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.7091 - accuracy: 0.0312\n",
      "Epoch 2: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 5.7084 - accuracy: 0.0310\n",
      "Epoch 3/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.5969 - accuracy: 0.0363\n",
      "Epoch 3: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 5.6049 - accuracy: 0.0360\n",
      "Epoch 4/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.5097 - accuracy: 0.0393\n",
      "Epoch 4: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 5.5121 - accuracy: 0.0390\n",
      "Epoch 5/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.4333 - accuracy: 0.0444\n",
      "Epoch 5: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 5.4284 - accuracy: 0.0450\n",
      "Epoch 6/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.3534 - accuracy: 0.0544\n",
      "Epoch 6: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 5.3534 - accuracy: 0.0540\n",
      "Epoch 7/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.2868 - accuracy: 0.0635\n",
      "Epoch 7: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 5.2842 - accuracy: 0.0630\n",
      "Epoch 8/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.2211 - accuracy: 0.0665\n",
      "Epoch 8: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 5.2126 - accuracy: 0.0690\n",
      "Epoch 9/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.1568 - accuracy: 0.0766\n",
      "Epoch 9: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 5.1518 - accuracy: 0.0760\n",
      "Epoch 10/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.0851 - accuracy: 0.0817\n",
      "Epoch 10: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 5.0879 - accuracy: 0.0820\n",
      "Epoch 11/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.0266 - accuracy: 0.0917\n",
      "Epoch 11: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 5.0272 - accuracy: 0.0910\n",
      "Epoch 12/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.9652 - accuracy: 0.0998\n",
      "Epoch 12: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.9700 - accuracy: 0.1000\n",
      "Epoch 13/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.9133 - accuracy: 0.1069\n",
      "Epoch 13: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.9104 - accuracy: 0.1070\n",
      "Epoch 14/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.8497 - accuracy: 0.1119\n",
      "Epoch 14: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.8537 - accuracy: 0.1130\n",
      "Epoch 15/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.8005 - accuracy: 0.1260\n",
      "Epoch 15: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.7993 - accuracy: 0.1260\n",
      "Epoch 16/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7369 - accuracy: 0.1341\n",
      "Epoch 16: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.7443 - accuracy: 0.1330\n",
      "Epoch 17/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.6858 - accuracy: 0.1411\n",
      "Epoch 17: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.6954 - accuracy: 0.1400\n",
      "Epoch 18/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.6429 - accuracy: 0.1452\n",
      "Epoch 18: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 4.6422 - accuracy: 0.1460\n",
      "Epoch 19/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.5911 - accuracy: 0.1522\n",
      "Epoch 19: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.5915 - accuracy: 0.1520\n",
      "Epoch 20/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.5396 - accuracy: 0.1573\n",
      "Epoch 20: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.5397 - accuracy: 0.1570\n",
      "Epoch 21/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.4890 - accuracy: 0.1734\n",
      "Epoch 21: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.4908 - accuracy: 0.1720\n",
      "Epoch 22/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.4466 - accuracy: 0.1794\n",
      "Epoch 22: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.4430 - accuracy: 0.1790\n",
      "Epoch 23/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.3955 - accuracy: 0.1825\n",
      "Epoch 23: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.3954 - accuracy: 0.1820\n",
      "Epoch 24/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.3469 - accuracy: 0.1905\n",
      "Epoch 24: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.3455 - accuracy: 0.1920\n",
      "Epoch 25/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.3000 - accuracy: 0.1966\n",
      "Epoch 25: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.2994 - accuracy: 0.1970\n",
      "Epoch 26/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.2545 - accuracy: 0.2067\n",
      "Epoch 26: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.2518 - accuracy: 0.2080\n",
      "Epoch 27/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.2127 - accuracy: 0.2167\n",
      "Epoch 27: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 53ms/step - loss: 4.2043 - accuracy: 0.2180\n",
      "Epoch 28/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.1541 - accuracy: 0.2298\n",
      "Epoch 28: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.1589 - accuracy: 0.2290\n",
      "Epoch 29/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.1071 - accuracy: 0.2359\n",
      "Epoch 29: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.1132 - accuracy: 0.2340\n",
      "Epoch 30/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.0684 - accuracy: 0.2440\n",
      "Epoch 30: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.0699 - accuracy: 0.2450\n",
      "Epoch 31/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.0190 - accuracy: 0.2560\n",
      "Epoch 31: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.0247 - accuracy: 0.2560\n",
      "Epoch 32/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 3.9757 - accuracy: 0.2681\n",
      "Epoch 32: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 3.9809 - accuracy: 0.2670\n",
      "Epoch 33/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 3.9346 - accuracy: 0.2742\n",
      "Epoch 33: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 3.9382 - accuracy: 0.2740\n",
      "Epoch 34/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 3.8978 - accuracy: 0.2883\n",
      "Epoch 34: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 64ms/step - loss: 3.8947 - accuracy: 0.2880\n",
      "\n",
      "Iteration = 30.0\n",
      "\n",
      "Epoch 1/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.8350 - accuracy: 0.0262\n",
      "Epoch 1: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 5.8417 - accuracy: 0.0260\n",
      "Epoch 2/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.7177 - accuracy: 0.0272\n",
      "Epoch 2: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 5.7197 - accuracy: 0.0270\n",
      "Epoch 3/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.6195 - accuracy: 0.0353\n",
      "Epoch 3: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 5.6220 - accuracy: 0.0350\n",
      "Epoch 4/34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/32 [============================>.] - ETA: 0s - loss: 5.5309 - accuracy: 0.0403\n",
      "Epoch 4: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 5.5348 - accuracy: 0.0400\n",
      "Epoch 5/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.4457 - accuracy: 0.0423\n",
      "Epoch 5: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 5.4540 - accuracy: 0.0420\n",
      "Epoch 6/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.3878 - accuracy: 0.0454\n",
      "Epoch 6: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 5.3785 - accuracy: 0.0470\n",
      "Epoch 7/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.3095 - accuracy: 0.0494\n",
      "Epoch 7: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 5.3094 - accuracy: 0.0490\n",
      "Epoch 8/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.2454 - accuracy: 0.0625\n",
      "Epoch 8: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 58ms/step - loss: 5.2417 - accuracy: 0.0630\n",
      "Epoch 9/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.1751 - accuracy: 0.0665\n",
      "Epoch 9: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 5.1756 - accuracy: 0.0660\n",
      "Epoch 10/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.1158 - accuracy: 0.0776\n",
      "Epoch 10: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 5.1133 - accuracy: 0.0770\n",
      "Epoch 11/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.0465 - accuracy: 0.0817\n",
      "Epoch 11: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 5.0520 - accuracy: 0.0810\n",
      "Epoch 12/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.9937 - accuracy: 0.0877\n",
      "Epoch 12: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.9948 - accuracy: 0.0870\n",
      "Epoch 13/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.9375 - accuracy: 0.0857\n",
      "Epoch 13: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.9379 - accuracy: 0.0870\n",
      "Epoch 14/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.8886 - accuracy: 0.0958\n",
      "Epoch 14: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.8835 - accuracy: 0.0970\n",
      "Epoch 15/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.8313 - accuracy: 0.0968\n",
      "Epoch 15: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.8279 - accuracy: 0.0990\n",
      "Epoch 16/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7762 - accuracy: 0.1119\n",
      "Epoch 16: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.7741 - accuracy: 0.1110\n",
      "Epoch 17/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7246 - accuracy: 0.1149\n",
      "Epoch 17: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.7229 - accuracy: 0.1150\n",
      "Epoch 18/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.6759 - accuracy: 0.1210\n",
      "Epoch 18: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.6700 - accuracy: 0.1220\n",
      "Epoch 19/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.6177 - accuracy: 0.1381\n",
      "Epoch 19: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.6189 - accuracy: 0.1380\n",
      "Epoch 20/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.5744 - accuracy: 0.1431\n",
      "Epoch 20: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.5693 - accuracy: 0.1450\n",
      "Epoch 21/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.5207 - accuracy: 0.1562\n",
      "Epoch 21: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.5201 - accuracy: 0.1570\n",
      "Epoch 22/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.4700 - accuracy: 0.1663\n",
      "Epoch 22: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.4699 - accuracy: 0.1660\n",
      "Epoch 23/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.4275 - accuracy: 0.1724\n",
      "Epoch 23: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.4240 - accuracy: 0.1730\n",
      "Epoch 24/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.3717 - accuracy: 0.1865\n",
      "Epoch 24: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.3756 - accuracy: 0.1850\n",
      "Epoch 25/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.3306 - accuracy: 0.1946\n",
      "Epoch 25: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.3272 - accuracy: 0.1950\n",
      "Epoch 26/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.2795 - accuracy: 0.2046\n",
      "Epoch 26: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.2808 - accuracy: 0.2030\n",
      "Epoch 27/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.2411 - accuracy: 0.2157\n",
      "Epoch 27: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 4.2351 - accuracy: 0.2180\n",
      "Epoch 28/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.1876 - accuracy: 0.2278\n",
      "Epoch 28: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.1879 - accuracy: 0.2280\n",
      "Epoch 29/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.1464 - accuracy: 0.2399\n",
      "Epoch 29: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.1447 - accuracy: 0.2400\n",
      "Epoch 30/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.1000 - accuracy: 0.2480\n",
      "Epoch 30: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.0999 - accuracy: 0.2470\n",
      "Epoch 31/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.0517 - accuracy: 0.2621\n",
      "Epoch 31: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 4.0548 - accuracy: 0.2610\n",
      "Epoch 32/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.0065 - accuracy: 0.2762\n",
      "Epoch 32: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 4.0108 - accuracy: 0.2750\n",
      "Epoch 33/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 3.9658 - accuracy: 0.2883\n",
      "Epoch 33: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 3.9685 - accuracy: 0.2880\n",
      "Epoch 34/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 3.9229 - accuracy: 0.2994\n",
      "Epoch 34: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 3.9248 - accuracy: 0.2970\n",
      "\n",
      "Iteration = 31.0\n",
      "\n",
      "Epoch 1/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.7934 - accuracy: 0.0282\n",
      "Epoch 1: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 5.7940 - accuracy: 0.0280\n",
      "Epoch 2/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.6825 - accuracy: 0.0353\n",
      "Epoch 2: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 5.6830 - accuracy: 0.0350\n",
      "Epoch 3/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.5884 - accuracy: 0.0454\n",
      "Epoch 3: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 5.5862 - accuracy: 0.0450\n",
      "Epoch 4/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.4986 - accuracy: 0.0504\n",
      "Epoch 4: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 5.5021 - accuracy: 0.0500\n",
      "Epoch 5/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.4244 - accuracy: 0.0575\n",
      "Epoch 5: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 53ms/step - loss: 5.4278 - accuracy: 0.0570\n",
      "Epoch 6/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.3571 - accuracy: 0.0605\n",
      "Epoch 6: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 5.3573 - accuracy: 0.0600\n",
      "Epoch 7/34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/32 [============================>.] - ETA: 0s - loss: 5.2934 - accuracy: 0.0655\n",
      "Epoch 7: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 53ms/step - loss: 5.2912 - accuracy: 0.0650\n",
      "Epoch 8/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.2225 - accuracy: 0.0685\n",
      "Epoch 8: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 5.2256 - accuracy: 0.0690\n",
      "Epoch 9/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.1626 - accuracy: 0.0756\n",
      "Epoch 9: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 5.1637 - accuracy: 0.0750\n",
      "Epoch 10/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.1023 - accuracy: 0.0746\n",
      "Epoch 10: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 58ms/step - loss: 5.1048 - accuracy: 0.0740\n",
      "Epoch 11/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.0510 - accuracy: 0.0887\n",
      "Epoch 11: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 5.0472 - accuracy: 0.0890\n",
      "Epoch 12/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.9903 - accuracy: 0.0938\n",
      "Epoch 12: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.9882 - accuracy: 0.0930\n",
      "Epoch 13/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.9352 - accuracy: 0.1038\n",
      "Epoch 13: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.9353 - accuracy: 0.1040\n",
      "Epoch 14/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.8779 - accuracy: 0.1109\n",
      "Epoch 14: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.8810 - accuracy: 0.1110\n",
      "Epoch 15/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.8323 - accuracy: 0.1149\n",
      "Epoch 15: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.8280 - accuracy: 0.1160\n",
      "Epoch 16/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7770 - accuracy: 0.1230\n",
      "Epoch 16: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.7759 - accuracy: 0.1220\n",
      "Epoch 17/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7263 - accuracy: 0.1230\n",
      "Epoch 17: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.7253 - accuracy: 0.1240\n",
      "Epoch 18/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.6745 - accuracy: 0.1280\n",
      "Epoch 18: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.6745 - accuracy: 0.1290\n",
      "Epoch 19/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.6346 - accuracy: 0.1361\n",
      "Epoch 19: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.6262 - accuracy: 0.1370\n",
      "Epoch 20/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.5821 - accuracy: 0.1492\n",
      "Epoch 20: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.5778 - accuracy: 0.1490\n",
      "Epoch 21/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.5208 - accuracy: 0.1573\n",
      "Epoch 21: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.5283 - accuracy: 0.1560\n",
      "Epoch 22/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.4864 - accuracy: 0.1633\n",
      "Epoch 22: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.4804 - accuracy: 0.1640\n",
      "Epoch 23/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.4349 - accuracy: 0.1754\n",
      "Epoch 23: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 4.4339 - accuracy: 0.1750\n",
      "Epoch 24/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.3897 - accuracy: 0.1784\n",
      "Epoch 24: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.3877 - accuracy: 0.1790\n",
      "Epoch 25/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.3396 - accuracy: 0.1895\n",
      "Epoch 25: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.3402 - accuracy: 0.1880\n",
      "Epoch 26/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.2928 - accuracy: 0.1976\n",
      "Epoch 26: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.2946 - accuracy: 0.1970\n",
      "Epoch 27/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.2556 - accuracy: 0.2067\n",
      "Epoch 27: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.2488 - accuracy: 0.2090\n",
      "Epoch 28/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.2056 - accuracy: 0.2218\n",
      "Epoch 28: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.2055 - accuracy: 0.2220\n",
      "Epoch 29/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.1606 - accuracy: 0.2359\n",
      "Epoch 29: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.1604 - accuracy: 0.2350\n",
      "Epoch 30/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.1154 - accuracy: 0.2470\n",
      "Epoch 30: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 4.1166 - accuracy: 0.2460\n",
      "Epoch 31/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.0751 - accuracy: 0.2520\n",
      "Epoch 31: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.0740 - accuracy: 0.2530\n",
      "Epoch 32/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.0343 - accuracy: 0.2621\n",
      "Epoch 32: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.0313 - accuracy: 0.2630\n",
      "Epoch 33/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 3.9868 - accuracy: 0.2732\n",
      "Epoch 33: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 3.9876 - accuracy: 0.2730\n",
      "Epoch 34/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 3.9459 - accuracy: 0.2792\n",
      "Epoch 34: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 3.9465 - accuracy: 0.2790\n",
      "\n",
      "Iteration = 32.0\n",
      "\n",
      "Epoch 1/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.8044 - accuracy: 0.0252\n",
      "Epoch 1: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 5.8071 - accuracy: 0.0250\n",
      "Epoch 2/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.6744 - accuracy: 0.0312\n",
      "Epoch 2: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 5.6698 - accuracy: 0.0320\n",
      "Epoch 3/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.5605 - accuracy: 0.0413\n",
      "Epoch 3: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 5.5617 - accuracy: 0.0410\n",
      "Epoch 4/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.4751 - accuracy: 0.0544\n",
      "Epoch 4: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 5.4690 - accuracy: 0.0550\n",
      "Epoch 5/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.3952 - accuracy: 0.0534\n",
      "Epoch 5: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 53ms/step - loss: 5.3886 - accuracy: 0.0540\n",
      "Epoch 6/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.3128 - accuracy: 0.0635\n",
      "Epoch 6: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 5.3118 - accuracy: 0.0640\n",
      "Epoch 7/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.2388 - accuracy: 0.0776\n",
      "Epoch 7: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 5.2396 - accuracy: 0.0780\n",
      "Epoch 8/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.1697 - accuracy: 0.0847\n",
      "Epoch 8: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 5.1721 - accuracy: 0.0850\n",
      "Epoch 9/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.1076 - accuracy: 0.0948\n",
      "Epoch 9: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 5.1090 - accuracy: 0.0950\n",
      "Epoch 10/34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/32 [============================>.] - ETA: 0s - loss: 5.0438 - accuracy: 0.1008\n",
      "Epoch 10: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 5.0429 - accuracy: 0.1010\n",
      "Epoch 11/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.9888 - accuracy: 0.0998\n",
      "Epoch 11: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.9843 - accuracy: 0.1020\n",
      "Epoch 12/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.9295 - accuracy: 0.1099\n",
      "Epoch 12: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.9248 - accuracy: 0.1100\n",
      "Epoch 13/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.8692 - accuracy: 0.1129\n",
      "Epoch 13: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.8671 - accuracy: 0.1140\n",
      "Epoch 14/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.8123 - accuracy: 0.1220\n",
      "Epoch 14: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 4.8130 - accuracy: 0.1210\n",
      "Epoch 15/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7565 - accuracy: 0.1260\n",
      "Epoch 15: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.7587 - accuracy: 0.1250\n",
      "Epoch 16/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7096 - accuracy: 0.1331\n",
      "Epoch 16: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.7066 - accuracy: 0.1350\n",
      "Epoch 17/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.6536 - accuracy: 0.1411\n",
      "Epoch 17: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.6534 - accuracy: 0.1410\n",
      "Epoch 18/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.6041 - accuracy: 0.1442\n",
      "Epoch 18: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.6006 - accuracy: 0.1460\n",
      "Epoch 19/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.5523 - accuracy: 0.1512\n",
      "Epoch 19: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.5509 - accuracy: 0.1510\n",
      "Epoch 20/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.5040 - accuracy: 0.1542\n",
      "Epoch 20: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.5015 - accuracy: 0.1550\n",
      "Epoch 21/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.4512 - accuracy: 0.1633\n",
      "Epoch 21: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.4503 - accuracy: 0.1640\n",
      "Epoch 22/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.3954 - accuracy: 0.1663\n",
      "Epoch 22: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.4011 - accuracy: 0.1660\n",
      "Epoch 23/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.3559 - accuracy: 0.1744\n",
      "Epoch 23: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.3546 - accuracy: 0.1740\n",
      "Epoch 24/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.3115 - accuracy: 0.1764\n",
      "Epoch 24: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.3063 - accuracy: 0.1790\n",
      "Epoch 25/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.2653 - accuracy: 0.1855\n",
      "Epoch 25: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.2595 - accuracy: 0.1880\n",
      "Epoch 26/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.2112 - accuracy: 0.1956\n",
      "Epoch 26: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.2131 - accuracy: 0.1950\n",
      "Epoch 27/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.1602 - accuracy: 0.2046\n",
      "Epoch 27: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.1659 - accuracy: 0.2040\n",
      "Epoch 28/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.1213 - accuracy: 0.2177\n",
      "Epoch 28: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.1208 - accuracy: 0.2170\n",
      "Epoch 29/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.0764 - accuracy: 0.2268\n",
      "Epoch 29: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.0754 - accuracy: 0.2280\n",
      "Epoch 30/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.0326 - accuracy: 0.2369\n",
      "Epoch 30: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.0313 - accuracy: 0.2380\n",
      "Epoch 31/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 3.9949 - accuracy: 0.2480\n",
      "Epoch 31: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 3.9848 - accuracy: 0.2500\n",
      "Epoch 32/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 3.9520 - accuracy: 0.2571\n",
      "Epoch 32: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 3.9425 - accuracy: 0.2580\n",
      "Epoch 33/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 3.8908 - accuracy: 0.2802\n",
      "Epoch 33: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 3.9011 - accuracy: 0.2800\n",
      "Epoch 34/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 3.8603 - accuracy: 0.2873\n",
      "Epoch 34: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 3.8570 - accuracy: 0.2900\n",
      "\n",
      "Iteration = 33.0\n",
      "\n",
      "Epoch 1/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.7669 - accuracy: 0.0252\n",
      "Epoch 1: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 5.7651 - accuracy: 0.0250\n",
      "Epoch 2/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.6353 - accuracy: 0.0333\n",
      "Epoch 2: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 5.6331 - accuracy: 0.0330\n",
      "Epoch 3/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.5259 - accuracy: 0.0373\n",
      "Epoch 3: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 5.5223 - accuracy: 0.0370\n",
      "Epoch 4/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.4239 - accuracy: 0.0444\n",
      "Epoch 4: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 5.4264 - accuracy: 0.0440\n",
      "Epoch 5/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.3403 - accuracy: 0.0413\n",
      "Epoch 5: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 5.3366 - accuracy: 0.0430\n",
      "Epoch 6/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.2569 - accuracy: 0.0524\n",
      "Epoch 6: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 5.2587 - accuracy: 0.0530\n",
      "Epoch 7/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.1815 - accuracy: 0.0585\n",
      "Epoch 7: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 5.1827 - accuracy: 0.0580\n",
      "Epoch 8/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.1124 - accuracy: 0.0685\n",
      "Epoch 8: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 5.1095 - accuracy: 0.0690\n",
      "Epoch 9/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.0530 - accuracy: 0.0796\n",
      "Epoch 9: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 5.0435 - accuracy: 0.0810\n",
      "Epoch 10/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.9791 - accuracy: 0.0847\n",
      "Epoch 10: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 52ms/step - loss: 4.9782 - accuracy: 0.0840\n",
      "Epoch 11/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.9111 - accuracy: 0.0968\n",
      "Epoch 11: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.9168 - accuracy: 0.0960\n",
      "Epoch 12/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.8509 - accuracy: 0.1048\n",
      "Epoch 12: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 4.8553 - accuracy: 0.1040\n",
      "Epoch 13/34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/32 [============================>.] - ETA: 0s - loss: 4.8041 - accuracy: 0.1048\n",
      "Epoch 13: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.7961 - accuracy: 0.1070\n",
      "Epoch 14/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7291 - accuracy: 0.1159\n",
      "Epoch 14: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.7369 - accuracy: 0.1150\n",
      "Epoch 15/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.6840 - accuracy: 0.1220\n",
      "Epoch 15: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.6819 - accuracy: 0.1210\n",
      "Epoch 16/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.6271 - accuracy: 0.1321\n",
      "Epoch 16: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.6269 - accuracy: 0.1320\n",
      "Epoch 17/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.5721 - accuracy: 0.1401\n",
      "Epoch 17: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.5724 - accuracy: 0.1400\n",
      "Epoch 18/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.5323 - accuracy: 0.1522\n",
      "Epoch 18: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.5207 - accuracy: 0.1540\n",
      "Epoch 19/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.4664 - accuracy: 0.1633\n",
      "Epoch 19: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 58ms/step - loss: 4.4673 - accuracy: 0.1630\n",
      "Epoch 20/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.4057 - accuracy: 0.1744\n",
      "Epoch 20: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.4160 - accuracy: 0.1740\n",
      "Epoch 21/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.3614 - accuracy: 0.1895\n",
      "Epoch 21: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.3687 - accuracy: 0.1880\n",
      "Epoch 22/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.3161 - accuracy: 0.1946\n",
      "Epoch 22: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.3206 - accuracy: 0.1940\n",
      "Epoch 23/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.2664 - accuracy: 0.2097\n",
      "Epoch 23: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.2689 - accuracy: 0.2090\n",
      "Epoch 24/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.2192 - accuracy: 0.2137\n",
      "Epoch 24: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.2202 - accuracy: 0.2140\n",
      "Epoch 25/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.1600 - accuracy: 0.2248\n",
      "Epoch 25: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.1712 - accuracy: 0.2240\n",
      "Epoch 26/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.1224 - accuracy: 0.2339\n",
      "Epoch 26: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.1274 - accuracy: 0.2340\n",
      "Epoch 27/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.0837 - accuracy: 0.2429\n",
      "Epoch 27: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.0777 - accuracy: 0.2430\n",
      "Epoch 28/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.0339 - accuracy: 0.2540\n",
      "Epoch 28: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.0314 - accuracy: 0.2560\n",
      "Epoch 29/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 3.9869 - accuracy: 0.2631\n",
      "Epoch 29: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 3.9866 - accuracy: 0.2630\n",
      "Epoch 30/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 3.9360 - accuracy: 0.2692\n",
      "Epoch 30: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 3.9422 - accuracy: 0.2680\n",
      "Epoch 31/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 3.8983 - accuracy: 0.2782\n",
      "Epoch 31: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 64ms/step - loss: 3.8987 - accuracy: 0.2790\n",
      "Epoch 32/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 3.8485 - accuracy: 0.2873\n",
      "Epoch 32: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 3.8539 - accuracy: 0.2860\n",
      "Epoch 33/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 3.8127 - accuracy: 0.2933\n",
      "Epoch 33: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 3.8121 - accuracy: 0.2950\n",
      "Epoch 34/34\n",
      "31/32 [============================>.] - ETA: 0s - loss: 3.7630 - accuracy: 0.3125\n",
      "Epoch 34: saving model to model2.ckpt\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 3.7675 - accuracy: 0.3110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "j = 29000\n",
    "for i in range(30000, 35000, 1000):\n",
    "    \n",
    "    print(\"Iteration = {}\".format(j/1000))\n",
    "    print()\n",
    "    model.fit(x_train[j:i], y_train[j:i], epochs = 34, callbacks = [callback])\n",
    "    j = i\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec761a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-2.6853155e-02, -1.7214794e-02, -1.7341308e-02, ...,\n",
       "          4.2582853e-03, -2.2197478e-02, -3.5641130e-02],\n",
       "        [-1.1511651e-02,  1.7147668e-02, -6.5485602e-03, ...,\n",
       "         -1.8216918e-03,  3.1926538e-04, -1.9856911e-02],\n",
       "        [-3.3879329e-02, -2.0199640e-02, -1.1035396e-02, ...,\n",
       "         -1.8273434e-02, -2.9550482e-02,  1.1052534e-02],\n",
       "        ...,\n",
       "        [ 2.8251639e-02,  1.6333427e-02, -2.8085630e-02, ...,\n",
       "         -3.4920014e-02, -7.1524307e-03, -2.5905628e-02],\n",
       "        [-2.3474010e-02, -2.2424242e-02,  1.4723068e-03, ...,\n",
       "         -3.5474915e-02,  2.0537885e-02,  9.5064826e-03],\n",
       "        [-1.9995827e-02,  1.0195472e-02, -4.6270368e-05, ...,\n",
       "          1.9590052e-02,  5.8224401e-03, -3.7158499e-03]], dtype=float32),\n",
       " array([-0.00770718, -0.00644885, -0.00217193, ..., -0.00486651,\n",
       "        -0.00606083, -0.00835553], dtype=float32),\n",
       " array([[ 0.01428699,  0.03301504, -0.01682446, ...,  0.03458656,\n",
       "          0.01505344,  0.02218592],\n",
       "        [-0.03902259, -0.0168405 , -0.0249086 , ..., -0.04403361,\n",
       "         -0.00564643, -0.03436561],\n",
       "        [ 0.00743506, -0.00444491, -0.01558653, ...,  0.02285359,\n",
       "          0.01064763,  0.00742284],\n",
       "        ...,\n",
       "        [-0.02373341, -0.03262993,  0.04151827, ...,  0.01747518,\n",
       "          0.04316948, -0.01797763],\n",
       "        [-0.02221769, -0.02726505,  0.03624816, ..., -0.03116726,\n",
       "          0.02843192,  0.01149329],\n",
       "        [ 0.02016084, -0.03106777,  0.04468744, ..., -0.0040258 ,\n",
       "         -0.01263049,  0.00085986]], dtype=float32),\n",
       " array([-0.03173917, -0.00736911, -0.00939613, ..., -0.0473768 ,\n",
       "         0.05506589, -0.00996376], dtype=float32),\n",
       " array([[ 0.00089777, -0.03919965, -0.04870471, ...,  0.04017062,\n",
       "          0.06488648,  0.04883554],\n",
       "        [ 0.02123244, -0.02076817,  0.04438061, ..., -0.00569844,\n",
       "          0.03825885, -0.0707524 ],\n",
       "        [ 0.00513956, -0.02508302, -0.04526111, ...,  0.04170574,\n",
       "          0.12734583, -0.14150675],\n",
       "        ...,\n",
       "        [ 0.01626278,  0.00402358,  0.00306764, ..., -0.04517612,\n",
       "         -0.0548009 ,  0.03267161],\n",
       "        [-0.01150517, -0.03852891,  0.00557604, ...,  0.03914893,\n",
       "         -0.13939741, -0.03954472],\n",
       "        [-0.01310112,  0.03380558, -0.01433882, ..., -0.04613103,\n",
       "         -0.02302618,  0.01996379]], dtype=float32),\n",
       " array([-0.02552126, -0.03585651,  0.00752245, ...,  0.04041623,\n",
       "         0.0026578 , -0.03933943], dtype=float32),\n",
       " array([[-0.03952157, -0.00622961, -0.00272959, ...,  0.01123585,\n",
       "          0.01729354, -0.03412712],\n",
       "        [-0.04886192,  0.03840771,  0.02025743, ..., -0.0149457 ,\n",
       "         -0.02697   ,  0.04613391],\n",
       "        [-0.03918535,  0.0226218 , -0.05184365, ..., -0.03968347,\n",
       "         -0.01895602, -0.0330945 ],\n",
       "        ...,\n",
       "        [-0.02808859,  0.03658913,  0.03493716, ..., -0.00879261,\n",
       "          0.00037353,  0.03943468],\n",
       "        [-0.09421682, -0.0470475 , -0.02814803, ..., -0.01455442,\n",
       "          0.01455157, -0.01877382],\n",
       "        [-0.05417431, -0.06328733, -0.07731167, ..., -0.11052729,\n",
       "          0.00381866,  0.01554479]], dtype=float32),\n",
       " array([-0.01412948, -0.01447765, -0.01922171, ..., -0.01385413,\n",
       "        -0.01580527, -0.02367455], dtype=float32),\n",
       " array([[ 2.72225589e-02, -6.97372556e-02, -1.32910861e-02, ...,\n",
       "         -8.09478164e-02, -4.76707853e-02, -6.81419894e-02],\n",
       "        [-1.12639689e-04,  4.44479622e-02, -4.77673225e-02, ...,\n",
       "         -5.57052791e-02,  1.06713101e-02, -4.12676595e-02],\n",
       "        [-5.64123020e-02,  8.86678323e-02, -7.11141005e-02, ...,\n",
       "         -5.45176603e-02,  3.91931534e-02,  4.24665064e-02],\n",
       "        ...,\n",
       "        [-5.81721310e-03, -2.47040950e-02, -1.23617195e-01, ...,\n",
       "          3.08961626e-02, -1.86744824e-01, -5.27197719e-02],\n",
       "        [-1.25090793e-01,  7.18071908e-02, -4.72861193e-02, ...,\n",
       "         -5.17569035e-02,  4.02533486e-02,  1.53771983e-02],\n",
       "        [-4.66208756e-02,  1.84344314e-02, -6.96299747e-02, ...,\n",
       "         -7.95276370e-03, -5.27716316e-02, -1.01054907e-02]], dtype=float32),\n",
       " array([ 1.27166495e-01, -1.29639745e-01,  1.85992330e-01, -5.26240647e-01,\n",
       "         4.29542884e-02, -8.14114138e-02,  7.79482499e-02, -6.38046116e-02,\n",
       "        -2.49077201e-01,  4.18723859e-02, -6.95910305e-02,  2.19156802e-01,\n",
       "         4.62972075e-01, -2.00685143e-01,  3.52542959e-02, -1.35200083e-01,\n",
       "        -1.73460662e-01,  1.26627330e-02,  1.70641810e-01,  1.90642744e-01,\n",
       "         1.87017813e-01, -4.17430013e-01, -1.60998583e-01, -2.45607877e+00,\n",
       "        -8.45946074e-02, -1.69176519e-01, -5.99255227e-02,  2.28552055e-02,\n",
       "         2.02210113e-01, -3.96433324e-01,  3.19803983e-01,  1.35379255e-01,\n",
       "        -3.05991620e-01, -1.16435550e-01, -2.34817818e-01, -4.40948039e-01,\n",
       "         1.94902524e-01,  9.36435610e-02, -6.83133423e-01, -2.56153613e-01,\n",
       "        -3.84855300e-01,  2.24851742e-01,  1.15245290e-01, -2.04492003e-01,\n",
       "        -2.86001205e-01, -2.90203001e-02, -8.08963403e-02, -1.39368296e-01,\n",
       "         6.43048063e-02,  8.51716995e-02,  2.42263362e-01, -3.51122677e-01,\n",
       "        -2.75294155e-01, -4.78734747e-02, -1.35434687e-01, -2.25037754e-01,\n",
       "        -2.65357882e-01, -4.25930135e-02, -1.62805498e-01,  2.90776759e-01,\n",
       "         1.78936888e-02, -2.45076314e-01, -2.37570477e+00, -4.57089037e-01,\n",
       "         8.09699818e-02,  4.77172062e-02, -4.25199091e-01,  1.85064450e-01,\n",
       "        -5.15886009e-01, -7.06188381e-01,  7.52042700e-03, -1.80049509e-01,\n",
       "         1.81357503e-01, -3.75720888e-01, -2.16635644e-01, -2.17331037e-01,\n",
       "        -4.03456807e-01, -3.22707891e-01, -6.94161057e-02, -5.01708500e-02,\n",
       "         2.43670061e-01,  4.03138787e-01, -4.73335944e-03, -3.00277323e-01,\n",
       "        -1.69670247e-02, -1.33287236e-01, -7.47013807e-01, -6.91773713e-01,\n",
       "        -3.06115299e-02,  2.45841861e-01, -5.85094392e-01, -4.24680710e-01,\n",
       "         3.95972617e-02,  7.91708976e-02,  1.11275919e-01,  9.98222157e-02,\n",
       "         3.72377068e-01,  1.62277341e-01, -2.54489303e-01, -7.35786021e-01,\n",
       "        -1.14690602e-01, -3.02706569e-01,  2.74047464e-01, -4.59474511e-03,\n",
       "         1.78017139e-01, -5.89489788e-02,  2.02962458e-01,  3.37181687e-01,\n",
       "        -4.30569835e-02,  2.14925800e-02, -1.10975504e-01, -1.56170964e-01,\n",
       "         8.06869566e-02, -7.07985014e-02, -4.23208654e-01, -1.99861266e-02,\n",
       "        -2.87168384e-01, -1.49609774e-01,  3.02627552e-02, -1.29976735e-01,\n",
       "         3.02717865e-01, -1.37978550e-02,  3.28335948e-02, -3.65654454e-02,\n",
       "        -7.04344928e-01,  1.64748043e-01,  9.25133526e-02, -1.82593450e-01,\n",
       "         8.62888172e-02,  1.45965787e-02,  8.41867849e-02, -9.78388116e-02,\n",
       "        -1.19224176e-01, -2.82296568e-01,  1.72760695e-01, -1.31783932e-01,\n",
       "         1.35716513e-01,  1.28015399e-01,  2.18096182e-01,  2.10482076e-01,\n",
       "         2.25417331e-01, -3.80177647e-02, -2.36641908e+00, -8.92565250e-01,\n",
       "        -6.66544735e-01, -1.59939855e-01, -2.72801310e-01,  1.34582609e-01,\n",
       "         1.09853938e-01,  1.48706064e-01, -4.42405313e-01, -1.11034594e-01,\n",
       "         3.62103015e-01, -4.58164178e-02, -5.01086786e-02, -2.13384051e-02,\n",
       "        -3.19602311e-01,  2.68080890e-01, -2.28441551e-01,  2.46874765e-02,\n",
       "         1.54021680e-01, -1.28306061e-01, -4.20599766e-02,  7.74023458e-02,\n",
       "        -1.20023708e-03,  6.03621639e-03, -1.50967002e-01, -1.58014111e-02,\n",
       "        -1.13501303e-01,  8.93206373e-02,  1.74246758e-01, -2.08832547e-02,\n",
       "         2.54076034e-01, -9.49774534e-02, -3.48791108e-02, -9.01450068e-02,\n",
       "        -2.63632506e-01, -4.05504286e-01,  4.02781274e-03, -4.39330757e-01,\n",
       "         5.17009832e-02, -1.38823807e-01, -3.07677928e-02, -2.26168469e-01,\n",
       "         6.82082325e-02, -4.18838821e-02, -7.81927705e-02, -1.38307577e-02,\n",
       "         5.25250733e-02,  3.24473158e-02,  4.23318194e-03, -1.05146334e-01,\n",
       "        -5.19319177e-01, -1.80393413e-01,  2.05036700e-01, -2.52416521e-01,\n",
       "        -6.18981384e-02, -1.20134540e-01,  8.27883929e-02,  1.59927040e-01,\n",
       "         5.84141761e-02,  4.25131172e-01,  1.55214056e-01, -4.20776308e-01,\n",
       "        -2.60418057e-01,  3.25722843e-02, -7.36881495e-01,  3.28151792e-01,\n",
       "        -4.83981371e-01, -1.53187335e-01,  1.15352556e-01,  6.20260686e-02,\n",
       "         6.65705130e-02, -2.43432999e-01, -1.24057224e-02, -4.34501767e-01,\n",
       "        -1.75088733e-01, -1.83201000e-01, -3.47957015e-01,  2.29908228e-01,\n",
       "        -3.70736182e-01, -2.76308388e-01, -1.29421994e-01, -1.01513326e-01,\n",
       "        -2.52333105e-01, -6.42669022e-01, -1.01617694e-01, -1.36150077e-01,\n",
       "        -2.41374731e+00,  2.38447919e-01, -7.35412315e-02, -1.74598455e-01,\n",
       "         1.45849679e-02, -3.13768506e-01,  1.10592075e-01,  2.52064578e-02,\n",
       "        -6.10052943e-01, -2.90073961e-01,  2.79338360e-01,  3.41881573e-01,\n",
       "        -3.15093100e-01,  1.16590999e-01, -8.14106464e-01,  3.61178547e-01,\n",
       "        -1.12440512e-01, -5.32983959e-01,  6.37079179e-02,  1.09995358e-01,\n",
       "         2.61527568e-01,  4.32655424e-01,  1.48169979e-01,  6.22154884e-02,\n",
       "         2.33760383e-02, -1.45077109e-02, -4.80735928e-01,  2.23657652e-03,\n",
       "         1.70824945e-01,  1.56963050e-01,  7.06369281e-02, -1.14000373e-01,\n",
       "        -8.81428048e-02, -2.91940849e-02, -2.16897741e-01,  1.54021308e-01,\n",
       "         3.20991687e-02, -2.35089496e-01, -3.93538624e-02, -2.88058609e-01,\n",
       "         4.88821805e-01,  1.33959994e-01, -2.28801459e-01,  2.95993071e-02,\n",
       "         9.75596369e-04, -2.87476152e-01, -5.46745658e-02, -3.25049087e-02,\n",
       "         3.10657233e-01, -1.69091865e-01, -2.21509375e-02, -1.32201277e-02,\n",
       "        -4.62573841e-02, -4.88748923e-02,  5.46391070e-01,  7.25431144e-02,\n",
       "        -8.00251365e-02,  1.66105822e-01, -3.20932090e-01, -2.05801532e-01,\n",
       "        -1.89902693e-01, -1.27511183e-02, -4.58019346e-01,  1.96519252e-02,\n",
       "         1.11226968e-01, -2.27018759e-01,  2.78406888e-01,  7.38095194e-02,\n",
       "         2.40013912e-01, -3.61927859e-02, -1.11322939e-01, -2.67430097e-01,\n",
       "         1.34581298e-01,  1.82333797e-01,  1.76115587e-01, -1.91180423e-01,\n",
       "        -1.37810215e-01, -1.70654908e-01, -3.54677439e-02,  3.60297598e-02,\n",
       "        -1.06916223e-02, -2.77023405e-01, -1.34967893e-01,  1.35934547e-01,\n",
       "         2.56514340e-03, -1.20153263e-01, -5.92701659e-02,  3.37141424e-01,\n",
       "        -2.09962323e-01,  1.85400788e-02, -1.30493104e-01,  1.82439074e-01,\n",
       "        -8.01307987e-03, -9.30484906e-02,  7.93864354e-02, -1.32144436e-01,\n",
       "        -2.46643364e-01,  4.23509955e-01, -4.16727543e-01,  5.92778437e-02,\n",
       "        -1.33140206e-01, -2.64938831e-01, -1.00838017e+00, -1.60199070e+00,\n",
       "        -5.43918371e-01, -4.35580164e-02, -1.01393068e+00, -1.69502214e-01,\n",
       "        -3.93233627e-01, -1.48402005e-01, -1.61353624e+00,  9.31209996e-02,\n",
       "        -2.81032056e-01,  9.99364331e-02, -4.06890035e-01,  3.27218324e-01,\n",
       "        -2.02471882e-01, -3.09209496e-01, -5.17327011e-01,  3.19723010e-01,\n",
       "         3.21268767e-01,  6.75420016e-02, -3.58051062e-01, -7.71710515e-01,\n",
       "        -1.85515597e-01, -5.77202678e-01, -5.33422887e-01,  3.56541388e-03,\n",
       "        -3.06087226e-01, -6.95409238e-01, -5.04135311e-01, -2.73139656e-01,\n",
       "         2.44350970e-01, -2.62671173e-01, -4.07156199e-01, -9.26779881e-02,\n",
       "        -1.95243761e-01, -4.96358052e-03,  5.25045156e-01, -8.65557790e-02,\n",
       "         1.65318713e-01,  1.75825790e-01,  6.34137690e-02, -2.69201696e-01,\n",
       "         2.07713768e-01,  4.77871336e-02, -1.01183958e-01,  3.95792544e-01,\n",
       "         5.66504756e-03,  4.41924259e-02, -2.05073819e-01, -6.68491498e-02,\n",
       "         3.07085477e-02, -1.31595984e-01,  3.01041573e-01,  2.99235117e-02,\n",
       "        -8.58489498e-02, -3.28519158e-02, -5.70126511e-02, -1.50040656e-01,\n",
       "        -2.63490468e-01, -5.77670261e-02, -1.63910553e-01,  6.05207719e-02,\n",
       "         6.37737438e-02,  3.20722640e-01, -4.31679964e-01, -1.72088489e-01,\n",
       "         1.17278308e-01,  1.38017565e-01, -3.36354703e-01, -2.51109540e-01,\n",
       "        -2.68829077e-01, -4.45948571e-01, -1.50479302e-01, -2.42462695e-01,\n",
       "         1.49452299e-01, -5.70633113e-02, -2.83655226e-01,  6.06001377e-01,\n",
       "        -2.81883150e-01, -4.35900658e-01,  3.46031100e-01], dtype=float32)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cdf9913",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cv = np.load('x_cv2.npy')\n",
    "y_cv = np.load('y_cv.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e8fcc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "train_pred = model.predict(x_train[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5eb23c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0000000e+00, 1.3856624e-38, 1.7502921e-38, ..., 9.9988079e-01,\n",
       "       9.9998021e-01, 9.9999869e-01], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a765add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365/365 [==============================] - 2s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81f591e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00243429, 0.00243268, 0.00243473, ..., 0.0024319 , 0.00243123,\n",
       "        0.00243604],\n",
       "       [0.00243429, 0.00243268, 0.00243473, ..., 0.0024319 , 0.00243123,\n",
       "        0.00243604],\n",
       "       [0.00243429, 0.00243268, 0.00243473, ..., 0.0024319 , 0.00243123,\n",
       "        0.00243604],\n",
       "       ...,\n",
       "       [0.00243429, 0.00243268, 0.00243473, ..., 0.0024319 , 0.00243123,\n",
       "        0.00243604],\n",
       "       [0.00243429, 0.00243268, 0.00243473, ..., 0.0024319 , 0.00243123,\n",
       "        0.00243604],\n",
       "       [0.00243429, 0.00243268, 0.00243473, ..., 0.0024319 , 0.00243123,\n",
       "        0.00243604]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0d0dd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cv_unique = np.unique(y_cv)\n",
    "y_cv2 = []\n",
    "for y in y_cv:\n",
    "    y1 = 0\n",
    "    for i in range(len(y_cv_unique)):\n",
    "        if y == y_cv_unique[i]:\n",
    "            y1 = i\n",
    "    y_cv2.append(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfcdefe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "621d7f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 96, 281,  51, ..., 290, 256, 271])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cv = np.array(y_cv2)\n",
    "y_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff73859",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff8a17fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m train_pred2 \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_pred\u001b[49m:\n\u001b[0;32m      3\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(arr)\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mmax\u001b[39m(arr))\n\u001b[0;32m      4\u001b[0m     train_pred2\u001b[38;5;241m.\u001b[39mappend(i)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_pred' is not defined"
     ]
    }
   ],
   "source": [
    "train_pred2 = []\n",
    "for arr in train_pred:\n",
    "    i = list(arr).index(max(arr))\n",
    "    train_pred2.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fabdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred2 = []\n",
    "for arr in train_pred:\n",
    "    i = list(arr).index(max(arr))\n",
    "    train_pred2.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84012085",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ef8c114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365/365 [==============================] - 2s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "cv_pred = model.predict(x_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48aee53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in cv_pred:\n",
    "    y = list(i).index(max(i))\n",
    "    y_pred.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4af5daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[237,\n",
       " 13,\n",
       " 327,\n",
       " 407,\n",
       " 407,\n",
       " 407,\n",
       " 296,\n",
       " 318,\n",
       " 407,\n",
       " 296,\n",
       " 296,\n",
       " 189,\n",
       " 189,\n",
       " 75,\n",
       " 189,\n",
       " 235,\n",
       " 407,\n",
       " 234,\n",
       " 296,\n",
       " 132,\n",
       " 151,\n",
       " 119,\n",
       " 6,\n",
       " 151,\n",
       " 158,\n",
       " 151,\n",
       " 322,\n",
       " 1,\n",
       " 296,\n",
       " 403,\n",
       " 6,\n",
       " 114,\n",
       " 107,\n",
       " 296,\n",
       " 119,\n",
       " 189,\n",
       " 189,\n",
       " 407,\n",
       " 193,\n",
       " 175,\n",
       " 409,\n",
       " 45,\n",
       " 114,\n",
       " 159,\n",
       " 175,\n",
       " 296,\n",
       " 403,\n",
       " 327,\n",
       " 189,\n",
       " 407,\n",
       " 193,\n",
       " 193,\n",
       " 114,\n",
       " 189,\n",
       " 296,\n",
       " 189,\n",
       " 297,\n",
       " 151,\n",
       " 75,\n",
       " 114,\n",
       " 381,\n",
       " 237,\n",
       " 407,\n",
       " 231,\n",
       " 151,\n",
       " 189,\n",
       " 381,\n",
       " 33,\n",
       " 407,\n",
       " 175,\n",
       " 72,\n",
       " 407,\n",
       " 407,\n",
       " 189,\n",
       " 114,\n",
       " 407,\n",
       " 159,\n",
       " 119,\n",
       " 407,\n",
       " 292,\n",
       " 13,\n",
       " 189,\n",
       " 193,\n",
       " 296,\n",
       " 407,\n",
       " 75,\n",
       " 193,\n",
       " 193,\n",
       " 105,\n",
       " 175,\n",
       " 75,\n",
       " 296,\n",
       " 234,\n",
       " 189,\n",
       " 296,\n",
       " 322,\n",
       " 296,\n",
       " 101,\n",
       " 193,\n",
       " 13,\n",
       " 92,\n",
       " 322,\n",
       " 296,\n",
       " 322,\n",
       " 114,\n",
       " 119,\n",
       " 189,\n",
       " 1,\n",
       " 114,\n",
       " 151,\n",
       " 92,\n",
       " 159,\n",
       " 296,\n",
       " 189,\n",
       " 92,\n",
       " 114,\n",
       " 407,\n",
       " 407,\n",
       " 189,\n",
       " 212,\n",
       " 189,\n",
       " 187,\n",
       " 407,\n",
       " 189,\n",
       " 72,\n",
       " 409,\n",
       " 13,\n",
       " 119,\n",
       " 119,\n",
       " 407,\n",
       " 407,\n",
       " 189,\n",
       " 254,\n",
       " 189,\n",
       " 242,\n",
       " 33,\n",
       " 6,\n",
       " 238,\n",
       " 296,\n",
       " 407,\n",
       " 13,\n",
       " 13,\n",
       " 189,\n",
       " 322,\n",
       " 407,\n",
       " 407,\n",
       " 114,\n",
       " 189,\n",
       " 206,\n",
       " 75,\n",
       " 75,\n",
       " 296,\n",
       " 193,\n",
       " 296,\n",
       " 340,\n",
       " 211,\n",
       " 407,\n",
       " 322,\n",
       " 1,\n",
       " 237,\n",
       " 151,\n",
       " 407,\n",
       " 235,\n",
       " 55,\n",
       " 409,\n",
       " 175,\n",
       " 407,\n",
       " 119,\n",
       " 114,\n",
       " 407,\n",
       " 254,\n",
       " 296,\n",
       " 189,\n",
       " 140,\n",
       " 189,\n",
       " 35,\n",
       " 231,\n",
       " 114,\n",
       " 407,\n",
       " 114,\n",
       " 189,\n",
       " 296,\n",
       " 13,\n",
       " 193,\n",
       " 407,\n",
       " 175,\n",
       " 296,\n",
       " 237,\n",
       " 189,\n",
       " 75,\n",
       " 189,\n",
       " 59,\n",
       " 189,\n",
       " 407,\n",
       " 189,\n",
       " 102,\n",
       " 119,\n",
       " 189,\n",
       " 296,\n",
       " 114,\n",
       " 407,\n",
       " 13,\n",
       " 409,\n",
       " 189,\n",
       " 189,\n",
       " 407,\n",
       " 189,\n",
       " 235,\n",
       " 119,\n",
       " 188,\n",
       " 13,\n",
       " 13,\n",
       " 238,\n",
       " 322,\n",
       " 114,\n",
       " 296,\n",
       " 189,\n",
       " 407,\n",
       " 231,\n",
       " 296,\n",
       " 189,\n",
       " 189,\n",
       " 381,\n",
       " 189,\n",
       " 119,\n",
       " 189,\n",
       " 237,\n",
       " 407,\n",
       " 189,\n",
       " 114,\n",
       " 322,\n",
       " 13,\n",
       " 189,\n",
       " 221,\n",
       " 92,\n",
       " 296,\n",
       " 296,\n",
       " 296,\n",
       " 204,\n",
       " 55,\n",
       " 13,\n",
       " 238,\n",
       " 340,\n",
       " 407,\n",
       " 296,\n",
       " 322,\n",
       " 75,\n",
       " 151,\n",
       " 407,\n",
       " 1,\n",
       " 189,\n",
       " 407,\n",
       " 75,\n",
       " 409,\n",
       " 13,\n",
       " 189,\n",
       " 322,\n",
       " 298,\n",
       " 340,\n",
       " 189,\n",
       " 114,\n",
       " 407,\n",
       " 296,\n",
       " 189,\n",
       " 235,\n",
       " 151,\n",
       " 407,\n",
       " 107,\n",
       " 189,\n",
       " 107,\n",
       " 407,\n",
       " 189,\n",
       " 407,\n",
       " 75,\n",
       " 114,\n",
       " 407,\n",
       " 189,\n",
       " 235,\n",
       " 322,\n",
       " 114,\n",
       " 119,\n",
       " 407,\n",
       " 407,\n",
       " 92,\n",
       " 407,\n",
       " 407,\n",
       " 407,\n",
       " 189,\n",
       " 231,\n",
       " 175,\n",
       " 407,\n",
       " 189,\n",
       " 296,\n",
       " 114,\n",
       " 175,\n",
       " 119,\n",
       " 1,\n",
       " 407,\n",
       " 407,\n",
       " 119,\n",
       " 75,\n",
       " 322,\n",
       " 407,\n",
       " 189,\n",
       " 322,\n",
       " 189,\n",
       " 296,\n",
       " 237,\n",
       " 119,\n",
       " 92,\n",
       " 193,\n",
       " 381,\n",
       " 175,\n",
       " 140,\n",
       " 189,\n",
       " 298,\n",
       " 340,\n",
       " 242,\n",
       " 407,\n",
       " 189,\n",
       " 254,\n",
       " 158,\n",
       " 407,\n",
       " 407,\n",
       " 159,\n",
       " 13,\n",
       " 114,\n",
       " 175,\n",
       " 119,\n",
       " 189,\n",
       " 175,\n",
       " 13,\n",
       " 407,\n",
       " 189,\n",
       " 407,\n",
       " 189,\n",
       " 296,\n",
       " 296,\n",
       " 238,\n",
       " 407,\n",
       " 189,\n",
       " 203,\n",
       " 13,\n",
       " 296,\n",
       " 235,\n",
       " 318,\n",
       " 75,\n",
       " 189,\n",
       " 407,\n",
       " 407,\n",
       " 296,\n",
       " 189,\n",
       " 13,\n",
       " 298,\n",
       " 1,\n",
       " 151,\n",
       " 189,\n",
       " 119,\n",
       " 343,\n",
       " 298,\n",
       " 407,\n",
       " 107,\n",
       " 407,\n",
       " 407,\n",
       " 13,\n",
       " 407,\n",
       " 75,\n",
       " 151,\n",
       " 407,\n",
       " 322,\n",
       " 407,\n",
       " 13,\n",
       " 102,\n",
       " 189,\n",
       " 159,\n",
       " 296,\n",
       " 151,\n",
       " 189,\n",
       " 193,\n",
       " 189,\n",
       " 13,\n",
       " 407,\n",
       " 379,\n",
       " 114,\n",
       " 407,\n",
       " 119,\n",
       " 92,\n",
       " 119,\n",
       " 189,\n",
       " 175,\n",
       " 188,\n",
       " 381,\n",
       " 238,\n",
       " 13,\n",
       " 151,\n",
       " 189,\n",
       " 221,\n",
       " 151,\n",
       " 101,\n",
       " 92,\n",
       " 189,\n",
       " 189,\n",
       " 189,\n",
       " 340,\n",
       " 407,\n",
       " 92,\n",
       " 296,\n",
       " 327,\n",
       " 158,\n",
       " 189,\n",
       " 293,\n",
       " 114,\n",
       " 407,\n",
       " 407,\n",
       " 407,\n",
       " 407,\n",
       " 407,\n",
       " 1,\n",
       " 92,\n",
       " 409,\n",
       " 124,\n",
       " 296,\n",
       " 45,\n",
       " 107,\n",
       " 340,\n",
       " 322,\n",
       " 189,\n",
       " 189,\n",
       " 407,\n",
       " 119,\n",
       " 407,\n",
       " 119,\n",
       " 407,\n",
       " 296,\n",
       " 266,\n",
       " 407,\n",
       " 407,\n",
       " 237,\n",
       " 13,\n",
       " 238,\n",
       " 235,\n",
       " 189,\n",
       " 381,\n",
       " 98,\n",
       " 151,\n",
       " 114,\n",
       " 237,\n",
       " 114,\n",
       " 237,\n",
       " 296,\n",
       " 187,\n",
       " 151,\n",
       " 296,\n",
       " 159,\n",
       " 92,\n",
       " 119,\n",
       " 189,\n",
       " 13,\n",
       " 75,\n",
       " 407,\n",
       " 296,\n",
       " 296,\n",
       " 151,\n",
       " 114,\n",
       " 13,\n",
       " 407,\n",
       " 189,\n",
       " 189,\n",
       " 189,\n",
       " 322,\n",
       " 75,\n",
       " 407,\n",
       " 407,\n",
       " 114,\n",
       " 409,\n",
       " 151,\n",
       " 407,\n",
       " 189,\n",
       " 407,\n",
       " 92,\n",
       " 407,\n",
       " 75,\n",
       " 296,\n",
       " 189,\n",
       " 175,\n",
       " 189,\n",
       " 340,\n",
       " 296,\n",
       " 114,\n",
       " 189,\n",
       " 92,\n",
       " 13,\n",
       " 407,\n",
       " 407,\n",
       " 251,\n",
       " 189,\n",
       " 189,\n",
       " 234,\n",
       " 189,\n",
       " 293,\n",
       " 189,\n",
       " 189,\n",
       " 403,\n",
       " 407,\n",
       " 409,\n",
       " 189,\n",
       " 237,\n",
       " 296,\n",
       " 198,\n",
       " 237,\n",
       " 189,\n",
       " 189,\n",
       " 296,\n",
       " 75,\n",
       " 407,\n",
       " 13,\n",
       " 256,\n",
       " 189,\n",
       " 189,\n",
       " 231,\n",
       " 407,\n",
       " 114,\n",
       " 296,\n",
       " 322,\n",
       " 296,\n",
       " 193,\n",
       " 189,\n",
       " 151,\n",
       " 151,\n",
       " 159,\n",
       " 189,\n",
       " 193,\n",
       " 114,\n",
       " 296,\n",
       " 174,\n",
       " 407,\n",
       " 296,\n",
       " 340,\n",
       " 296,\n",
       " 75,\n",
       " 296,\n",
       " 407,\n",
       " 340,\n",
       " 296,\n",
       " 13,\n",
       " 235,\n",
       " 189,\n",
       " 189,\n",
       " 189,\n",
       " 238,\n",
       " 92,\n",
       " 254,\n",
       " 189,\n",
       " 203,\n",
       " 296,\n",
       " 159,\n",
       " 384,\n",
       " 407,\n",
       " 92,\n",
       " 296,\n",
       " 327,\n",
       " 296,\n",
       " 13,\n",
       " 296,\n",
       " 237,\n",
       " 13,\n",
       " 407,\n",
       " 140,\n",
       " 407,\n",
       " 158,\n",
       " 75,\n",
       " 407,\n",
       " 75,\n",
       " 104,\n",
       " 212,\n",
       " 114,\n",
       " 55,\n",
       " 114,\n",
       " 407,\n",
       " 189,\n",
       " 6,\n",
       " 407,\n",
       " 327,\n",
       " 407,\n",
       " 151,\n",
       " 296,\n",
       " 407,\n",
       " 407,\n",
       " 296,\n",
       " 151,\n",
       " 151,\n",
       " 296,\n",
       " 296,\n",
       " 140,\n",
       " 189,\n",
       " 175,\n",
       " 75,\n",
       " 189,\n",
       " 114,\n",
       " 407,\n",
       " 1,\n",
       " 189,\n",
       " 237,\n",
       " 407,\n",
       " 114,\n",
       " 75,\n",
       " 1,\n",
       " 407,\n",
       " 407,\n",
       " 75,\n",
       " 189,\n",
       " 13,\n",
       " 114,\n",
       " 296,\n",
       " 296,\n",
       " 189,\n",
       " 298,\n",
       " 189,\n",
       " 174,\n",
       " 212,\n",
       " 237,\n",
       " 189,\n",
       " 159,\n",
       " 238,\n",
       " 151,\n",
       " 13,\n",
       " 407,\n",
       " 242,\n",
       " 296,\n",
       " 189,\n",
       " 403,\n",
       " 189,\n",
       " 107,\n",
       " 407,\n",
       " 92,\n",
       " 15,\n",
       " 114,\n",
       " 297,\n",
       " 189,\n",
       " 189,\n",
       " 151,\n",
       " 296,\n",
       " 189,\n",
       " 189,\n",
       " 296,\n",
       " 296,\n",
       " 296,\n",
       " 407,\n",
       " 296,\n",
       " 189,\n",
       " 238,\n",
       " 407,\n",
       " 238,\n",
       " 407,\n",
       " 296,\n",
       " 114,\n",
       " 189,\n",
       " 403,\n",
       " 296,\n",
       " 407,\n",
       " 407,\n",
       " 322,\n",
       " 407,\n",
       " 158,\n",
       " 159,\n",
       " 75,\n",
       " 340,\n",
       " 189,\n",
       " 13,\n",
       " 296,\n",
       " 75,\n",
       " 13,\n",
       " 296,\n",
       " 296,\n",
       " 296,\n",
       " 237,\n",
       " 189,\n",
       " 296,\n",
       " 45,\n",
       " 119,\n",
       " 407,\n",
       " 114,\n",
       " 189,\n",
       " 119,\n",
       " 193,\n",
       " 282,\n",
       " 75,\n",
       " 175,\n",
       " 189,\n",
       " 189,\n",
       " 407,\n",
       " 114,\n",
       " 189,\n",
       " 92,\n",
       " 407,\n",
       " 407,\n",
       " 407,\n",
       " 189,\n",
       " 189,\n",
       " 1,\n",
       " 92,\n",
       " 381,\n",
       " 409,\n",
       " 407,\n",
       " 159,\n",
       " 407,\n",
       " 340,\n",
       " 45,\n",
       " 13,\n",
       " 407,\n",
       " 193,\n",
       " 407,\n",
       " 189,\n",
       " 13,\n",
       " 407,\n",
       " 13,\n",
       " 188,\n",
       " 407,\n",
       " 92,\n",
       " 296,\n",
       " 288,\n",
       " 296,\n",
       " 140,\n",
       " 407,\n",
       " 189,\n",
       " 407,\n",
       " 193,\n",
       " 407,\n",
       " 104,\n",
       " 407,\n",
       " 296,\n",
       " 114,\n",
       " 296,\n",
       " 107,\n",
       " 189,\n",
       " 407,\n",
       " 13,\n",
       " 119,\n",
       " 189,\n",
       " 322,\n",
       " 159,\n",
       " 114,\n",
       " 189,\n",
       " 407,\n",
       " 189,\n",
       " 407,\n",
       " 189,\n",
       " 189,\n",
       " 189,\n",
       " 189,\n",
       " 296,\n",
       " 204,\n",
       " 296,\n",
       " 237,\n",
       " 189,\n",
       " 114,\n",
       " 296,\n",
       " 296,\n",
       " 407,\n",
       " 407,\n",
       " 238,\n",
       " 193,\n",
       " 189,\n",
       " 407,\n",
       " 407,\n",
       " 189,\n",
       " 296,\n",
       " 151,\n",
       " 403,\n",
       " 407,\n",
       " 75,\n",
       " 189,\n",
       " 189,\n",
       " 407,\n",
       " 238,\n",
       " 140,\n",
       " 189,\n",
       " 203,\n",
       " 407,\n",
       " 189,\n",
       " 238,\n",
       " 407,\n",
       " 75,\n",
       " 407,\n",
       " 235,\n",
       " 237,\n",
       " 296,\n",
       " 315,\n",
       " 6,\n",
       " 390,\n",
       " 175,\n",
       " 114,\n",
       " 175,\n",
       " 293,\n",
       " 322,\n",
       " 189,\n",
       " 189,\n",
       " 296,\n",
       " 189,\n",
       " 235,\n",
       " 189,\n",
       " 101,\n",
       " 296,\n",
       " 296,\n",
       " 140,\n",
       " 13,\n",
       " 296,\n",
       " 189,\n",
       " 393,\n",
       " 114,\n",
       " 296,\n",
       " 92,\n",
       " 92,\n",
       " 151,\n",
       " 407,\n",
       " 407,\n",
       " 407,\n",
       " 407,\n",
       " 189,\n",
       " 189,\n",
       " 189,\n",
       " 189,\n",
       " 296,\n",
       " 238,\n",
       " 6,\n",
       " 189,\n",
       " 254,\n",
       " 407,\n",
       " 407,\n",
       " 189,\n",
       " 119,\n",
       " 189,\n",
       " 296,\n",
       " 119,\n",
       " 13,\n",
       " 407,\n",
       " 119,\n",
       " 407,\n",
       " 189,\n",
       " 151,\n",
       " 296,\n",
       " 75,\n",
       " 189,\n",
       " 296,\n",
       " 407,\n",
       " 407,\n",
       " 189,\n",
       " 114,\n",
       " 189,\n",
       " 193,\n",
       " 92,\n",
       " 340,\n",
       " 235,\n",
       " 407,\n",
       " 407,\n",
       " 407,\n",
       " 407,\n",
       " 189,\n",
       " 234,\n",
       " 13,\n",
       " 407,\n",
       " 1,\n",
       " 175,\n",
       " 407,\n",
       " 159,\n",
       " 237,\n",
       " 189,\n",
       " 119,\n",
       " 407,\n",
       " 296,\n",
       " 188,\n",
       " 189,\n",
       " 189,\n",
       " 407,\n",
       " 114,\n",
       " 189,\n",
       " 75,\n",
       " 114,\n",
       " 407,\n",
       " 238,\n",
       " 237,\n",
       " 114,\n",
       " 407,\n",
       " 132,\n",
       " 235,\n",
       " 237,\n",
       " 189,\n",
       " 238,\n",
       " 140,\n",
       " 189,\n",
       " 407,\n",
       " 193,\n",
       " 296,\n",
       " 238,\n",
       " 296,\n",
       " 296,\n",
       " 151,\n",
       " 403,\n",
       " 204,\n",
       " 189,\n",
       " 212,\n",
       " 212,\n",
       " 107,\n",
       " 322,\n",
       " 193,\n",
       " 235,\n",
       " 13,\n",
       " 189,\n",
       " 296,\n",
       " 140,\n",
       " 114,\n",
       " 403,\n",
       " 296,\n",
       " 296,\n",
       " 189,\n",
       " 151,\n",
       " 407,\n",
       " 189,\n",
       " 189,\n",
       " 407,\n",
       " 407,\n",
       " 13,\n",
       " 384,\n",
       " 175,\n",
       " 407,\n",
       " 119,\n",
       " 381,\n",
       " 407,\n",
       " 119,\n",
       " 114,\n",
       " 92,\n",
       " 151,\n",
       " 407,\n",
       " 119,\n",
       " 119,\n",
       " 407,\n",
       " 1,\n",
       " 407,\n",
       " 189,\n",
       " 75,\n",
       " 114,\n",
       " 75,\n",
       " 407,\n",
       " 158,\n",
       " 189,\n",
       " 6,\n",
       " 75,\n",
       " 189,\n",
       " 407,\n",
       " 407,\n",
       " 107,\n",
       " 238,\n",
       " 407,\n",
       " 189,\n",
       " 138,\n",
       " 212,\n",
       " 293,\n",
       " 75,\n",
       " 92,\n",
       " 407,\n",
       " 189,\n",
       " 189,\n",
       " 140,\n",
       " 237,\n",
       " 407,\n",
       " 13,\n",
       " 237,\n",
       " 407,\n",
       " 175,\n",
       " 407,\n",
       " 407,\n",
       " 189,\n",
       " 114,\n",
       " 381,\n",
       " 409,\n",
       " 237,\n",
       " 407,\n",
       " 189,\n",
       " 407,\n",
       " 407,\n",
       " 193,\n",
       " 75,\n",
       " 322,\n",
       " 238,\n",
       " 189,\n",
       " 266,\n",
       " 189,\n",
       " 407,\n",
       " 189,\n",
       " 237,\n",
       " 296,\n",
       " 407,\n",
       " 189,\n",
       " 296,\n",
       " 189,\n",
       " 407,\n",
       " 189,\n",
       " 322,\n",
       " 193,\n",
       " 407,\n",
       " ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b77a570",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 96, 281,  51, ..., 290, 256, 271])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b076c52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365/365 [==============================] - 2s 6ms/step - loss: 12.5193 - accuracy: 0.0034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[12.519343376159668, 0.0034252440091222525]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_cv[:34000], y_cv[:34000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "629c1bf2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mscore\u001b[49m[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'score' is not defined"
     ]
    }
   ],
   "source": [
    "score[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6b4eb9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([148])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80873f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "feb018e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_cv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:211\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "accuracy_score(y_cv, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
